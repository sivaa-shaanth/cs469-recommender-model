{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sivaa-shaanth/cs469-recommender-model/blob/main/Recommender_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIr2aucu_eBb"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jdrkmaz0--9C"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import torch\n",
        "from collections import defaultdict\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXGvz-37_MC7",
        "outputId": "492b51a0-fc49-49d4-fd68-9ddc5a727780"
      },
      "source": [
        "print(\"Downloading movielens data...\")\n",
        "from urllib.request import urlretrieve\n",
        "import zipfile\n",
        "\n",
        "urlretrieve (\"https://github.com/aravindsankar28/Recommender-Models/blob/main/ml-100k.zip?raw=true\", \"ml-100k.zip\")\n",
        "zip_ref = zipfile.ZipFile('ml-100k.zip', \"r\")\n",
        "\n",
        "zip_ref.extractall()\n",
        "print(\"Done. Dataset contains:\")\n",
        "print(zip_ref.read('ml-100k/u.info'))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading movielens data...\n",
            "Done. Dataset contains:\n",
            "b'943 users\\n1682 items\\n100000 ratings\\n'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twRPawct--9M"
      },
      "source": [
        "We first load the MovieLens Data, and create DataFrames containing movies, users, and ratings.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkEPwkfp--9N"
      },
      "source": [
        "# Load each data set (users, movies, and ratings).\n",
        "users_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
        "users = pd.read_csv(\n",
        "    'ml-100k/u.user', sep='|', names=users_cols, encoding='latin-1')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwwri0pY--9O"
      },
      "source": [
        "ratings_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
        "ratings = pd.read_csv(\n",
        "    'ml-100k/u.data', sep='\\t', names=ratings_cols, encoding='latin-1')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScSHwAks--9O"
      },
      "source": [
        "genre_cols = [\n",
        "    \"genre_unknown\", \"Action\", \"Adventure\", \"Animation\", \"Children\", \"Comedy\",\n",
        "    \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\", \"Horror\",\n",
        "    \"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\"\n",
        "]\n",
        "\n",
        "movies_cols = [\n",
        "    'movie_id', 'title', 'release_date', \"video_release_date\", \"imdb_url\"\n",
        "] + genre_cols\n",
        "\n",
        "movies = pd.read_csv(\n",
        "    'ml-100k/u.item', sep='|', names=movies_cols, encoding='latin-1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3f6qEgO--9P"
      },
      "source": [
        "# Since the ids start at 1, we shift them to start at 0.\n",
        "users[\"user_id\"] = users[\"user_id\"].apply(lambda x: int(x-1))\n",
        "movies[\"movie_id\"] = movies[\"movie_id\"].apply(lambda x: int(x-1))\n",
        "movies[\"year\"] = movies['release_date'].apply(lambda x: str(x).split('-')[-1])\n",
        "ratings[\"movie_id\"] = ratings[\"movie_id\"].apply(lambda x: int(x-1))\n",
        "ratings[\"user_id\"] = ratings[\"user_id\"].apply(lambda x: int(x-1))\n",
        "ratings[\"rating\"] = ratings[\"rating\"].apply(lambda x: float(x))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gd_0Ti4---9Q"
      },
      "source": [
        "movielens = ratings.merge(movies, on='movie_id').merge(users, on='user_id')\n",
        "movielens = movielens.drop(columns = [\"video_release_date\", \"imdb_url\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "KGe0G4pt--9Q",
        "outputId": "2aa2aede-6e30-42a6-c038-e131e7f6a6d5"
      },
      "source": [
        "movielens.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   user_id  movie_id  rating  unix_timestamp  \\\n",
              "0      195       241     3.0       881250949   \n",
              "1      195       256     2.0       881251577   \n",
              "2      195       110     4.0       881251793   \n",
              "3      195        24     4.0       881251955   \n",
              "4      195       381     4.0       881251843   \n",
              "\n",
              "                                               title release_date  \\\n",
              "0                                       Kolya (1996)  24-Jan-1997   \n",
              "1                                Men in Black (1997)  04-Jul-1997   \n",
              "2                Truth About Cats & Dogs, The (1996)  26-Apr-1996   \n",
              "3                               Birdcage, The (1996)  08-Mar-1996   \n",
              "4  Adventures of Priscilla, Queen of the Desert, ...  01-Jan-1994   \n",
              "\n",
              "   genre_unknown  Action  Adventure  Animation  ...  Romance  Sci-Fi  \\\n",
              "0              0       0          0          0  ...        0       0   \n",
              "1              0       1          1          0  ...        0       1   \n",
              "2              0       0          0          0  ...        1       0   \n",
              "3              0       0          0          0  ...        0       0   \n",
              "4              0       0          0          0  ...        0       0   \n",
              "\n",
              "   Thriller  War  Western  year  age  sex  occupation  zip_code  \n",
              "0         0    0        0  1997   49    M      writer     55105  \n",
              "1         0    0        0  1997   49    M      writer     55105  \n",
              "2         0    0        0  1996   49    M      writer     55105  \n",
              "3         0    0        0  1996   49    M      writer     55105  \n",
              "4         0    0        0  1994   49    M      writer     55105  \n",
              "\n",
              "[5 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-68a99f4a-a5cc-469f-b7f9-f2a99f6a10b9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>movie_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>unix_timestamp</th>\n",
              "      <th>title</th>\n",
              "      <th>release_date</th>\n",
              "      <th>genre_unknown</th>\n",
              "      <th>Action</th>\n",
              "      <th>Adventure</th>\n",
              "      <th>Animation</th>\n",
              "      <th>...</th>\n",
              "      <th>Romance</th>\n",
              "      <th>Sci-Fi</th>\n",
              "      <th>Thriller</th>\n",
              "      <th>War</th>\n",
              "      <th>Western</th>\n",
              "      <th>year</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>occupation</th>\n",
              "      <th>zip_code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>195</td>\n",
              "      <td>241</td>\n",
              "      <td>3.0</td>\n",
              "      <td>881250949</td>\n",
              "      <td>Kolya (1996)</td>\n",
              "      <td>24-Jan-1997</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1997</td>\n",
              "      <td>49</td>\n",
              "      <td>M</td>\n",
              "      <td>writer</td>\n",
              "      <td>55105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>195</td>\n",
              "      <td>256</td>\n",
              "      <td>2.0</td>\n",
              "      <td>881251577</td>\n",
              "      <td>Men in Black (1997)</td>\n",
              "      <td>04-Jul-1997</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1997</td>\n",
              "      <td>49</td>\n",
              "      <td>M</td>\n",
              "      <td>writer</td>\n",
              "      <td>55105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>195</td>\n",
              "      <td>110</td>\n",
              "      <td>4.0</td>\n",
              "      <td>881251793</td>\n",
              "      <td>Truth About Cats &amp; Dogs, The (1996)</td>\n",
              "      <td>26-Apr-1996</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1996</td>\n",
              "      <td>49</td>\n",
              "      <td>M</td>\n",
              "      <td>writer</td>\n",
              "      <td>55105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>195</td>\n",
              "      <td>24</td>\n",
              "      <td>4.0</td>\n",
              "      <td>881251955</td>\n",
              "      <td>Birdcage, The (1996)</td>\n",
              "      <td>08-Mar-1996</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1996</td>\n",
              "      <td>49</td>\n",
              "      <td>M</td>\n",
              "      <td>writer</td>\n",
              "      <td>55105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>195</td>\n",
              "      <td>381</td>\n",
              "      <td>4.0</td>\n",
              "      <td>881251843</td>\n",
              "      <td>Adventures of Priscilla, Queen of the Desert, ...</td>\n",
              "      <td>01-Jan-1994</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1994</td>\n",
              "      <td>49</td>\n",
              "      <td>M</td>\n",
              "      <td>writer</td>\n",
              "      <td>55105</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-68a99f4a-a5cc-469f-b7f9-f2a99f6a10b9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-68a99f4a-a5cc-469f-b7f9-f2a99f6a10b9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-68a99f4a-a5cc-469f-b7f9-f2a99f6a10b9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EdwQzxi--9S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "f794d9d2-1ace-4b6e-fe84-6ef1ac056390"
      },
      "source": [
        "def flatten_cols(df):\n",
        "    df.columns = [' '.join(col).strip() for col in df.columns.values]\n",
        "    return df\n",
        "\n",
        "pd.DataFrame.flatten_cols = flatten_cols\n",
        "\n",
        "users_ratings = (\n",
        "    ratings\n",
        "    .groupby('user_id', as_index=False)\n",
        "    .agg({'rating': ['count', 'mean']})\n",
        "    .flatten_cols()\n",
        "    .merge(users, on='user_id')\n",
        ")\n",
        "\n",
        "users_ratings.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   user_id  rating count  rating mean  age sex  occupation zip_code\n",
              "0        0           272     3.610294   24   M  technician    85711\n",
              "1        1            62     3.709677   53   F       other    94043\n",
              "2        2            54     2.796296   23   M      writer    32067\n",
              "3        3            24     4.333333   24   M  technician    43537\n",
              "4        4           175     2.874286   33   F       other    15213"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fb315e42-5349-41d6-a350-e173b9e66237\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>rating count</th>\n",
              "      <th>rating mean</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>occupation</th>\n",
              "      <th>zip_code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>272</td>\n",
              "      <td>3.610294</td>\n",
              "      <td>24</td>\n",
              "      <td>M</td>\n",
              "      <td>technician</td>\n",
              "      <td>85711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>62</td>\n",
              "      <td>3.709677</td>\n",
              "      <td>53</td>\n",
              "      <td>F</td>\n",
              "      <td>other</td>\n",
              "      <td>94043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>54</td>\n",
              "      <td>2.796296</td>\n",
              "      <td>23</td>\n",
              "      <td>M</td>\n",
              "      <td>writer</td>\n",
              "      <td>32067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>24</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>24</td>\n",
              "      <td>M</td>\n",
              "      <td>technician</td>\n",
              "      <td>43537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>175</td>\n",
              "      <td>2.874286</td>\n",
              "      <td>33</td>\n",
              "      <td>F</td>\n",
              "      <td>other</td>\n",
              "      <td>15213</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fb315e42-5349-41d6-a350-e173b9e66237')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fb315e42-5349-41d6-a350-e173b9e66237 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fb315e42-5349-41d6-a350-e173b9e66237');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ6OXd0i--9T"
      },
      "source": [
        "### Question 1: Rating Distribution of users.\n",
        "First, we look at the distribution of ratings per user to examine number of ratings and average rating per user.\n",
        "\n",
        "Plot two histograms depicting: (a) the number of ratings per user and (b) average rating per user. (Use plt.hist with 10 bins)\n",
        "\n",
        "What do you observe?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-uvSfrZ--9T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "outputId": "94519930-2374-4bd5-c5bd-149748a459c0"
      },
      "source": [
        "#plot the number of ratings per user\n",
        "plt.hist(users_ratings['rating count'], bins=100)\n",
        "plt.xlabel('Number of ratings')\n",
        "plt.ylabel('Number of users')\n",
        "plt.title('Number of ratings per user')\n",
        "plt.show()\n",
        "\n",
        "#plot the average rating per user\n",
        "plt.hist(users_ratings['rating mean'], bins=100)\n",
        "plt.xlabel('Average rating')\n",
        "plt.ylabel('Number of users')\n",
        "plt.title('Average rating per user')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAHHCAYAAABZbpmkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABF40lEQVR4nO3deVhV1f7H8c8B5ODAICgiqaA4z1OSaWVJIZpp2aBpOaUNmjlUSlkOv65gg3n1ml4b1FuWTWqlqTmgljmkSQ6VIw43xVkQLRRYvz98PLcjqBw4CGzfr+fZz+Nee529v+scgk9rD8dmjDECAACwKI/CLgAAAKAgEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXaAYm7lypWy2Wz64osvCruUXDly5IgefPBBBQUFyWazaeLEiYVSx+jRo2Wz2Qrl2ACuL8IOkAszZ86UzWaTj4+P/vjjj2zb27Rpo/r16xdCZcXPkCFDtGTJEsXGxurDDz9Uu3btCuxY586d0+jRo7Vy5coCOwaAoo+wA7ggPT1d8fHxhV1GsbZixQp16tRJzz//vHr06KHatWsX2LHOnTunMWPG5Bh2Ro4cqT///LPAjg2g6CDsAC5o3Lix3n33XR06dKiwS7nuzp4965b9HD16VAEBAXl6bUZGhs6fP++WOry8vOTj4+OWfRVXf/31l7Kysgq7jGty188eblyEHcAFL730kjIzM685u7Nv3z7ZbDbNnDkz2zabzabRo0c71i9dO7Jz50716NFD/v7+Kl++vF555RUZY3Tw4EF16tRJfn5+CgkJ0VtvvZXjMTMzM/XSSy8pJCREpUuX1n333aeDBw9m67d+/Xq1a9dO/v7+KlWqlO644w6tWbPGqc+lmn799Vc9+uijKlu2rFq3bn3VMe/du1cPPfSQAgMDVapUKd1yyy1auHChY/ulU4HGGE2ZMkU2m+2q18xceg/ffPNNTZw4UREREbLb7fr11191/vx5vfrqq2rWrJn8/f1VunRp3XbbbUpISHB6ffny5SVJY8aMcRzv0nuf0zU7NptNAwcO1Pz581W/fn3Z7XbVq1dPixcvzlbfypUr1bx5c/n4+CgiIkL//ve/c9zn0qVL1bp1awUEBKhMmTKqVauWXnrppau+l3+vZfbs2apVq5Z8fHzUrFkzrV69OlvfP/74Q3369FGFChUcNX/wwQfZ6rXZbJozZ45Gjhypm266SaVKlVJqamqOx7/U//JZsZx+tpOTk9W7d29VqlRJdrtdFStWVKdOnbRv3z6n1y5atEi33XabSpcuLV9fX3Xo0EHbt2936tOrVy+VKVNGe/bsUfv27eXr66vu3btf8/0CrsarsAsAipOqVavq8ccf17vvvqsRI0YoNDTUbft+5JFHVKdOHcXHx2vhwoV67bXXFBgYqH//+9+66667NH78eM2ePVvPP/+8br75Zt1+++1Or//HP/4hm82m4cOH6+jRo5o4caKioqKUmJiokiVLSrp4CikmJkbNmjXTqFGj5OHhoRkzZuiuu+7S999/rxYtWjjt86GHHlKNGjU0btw4GWOuWPuRI0d066236ty5cxo0aJCCgoI0a9Ys3Xffffriiy90//336/bbb9eHH36oxx57THfffbcef/zxXL0vM2bM0F9//aX+/fvLbrcrMDBQqampeu+999StWzf169dPZ86c0fvvv6/o6Ght2LBBjRs3Vvny5TV16lQ9/fTTuv/++/XAAw9Ikho2bHjV4/3www+aO3eunnnmGfn6+mrSpEnq0qWLDhw4oKCgIEnS5s2b1a5dO1WsWFFjxoxRZmamxo4d6whXl2zfvl333nuvGjZsqLFjx8put2v37t3ZwuWVrFq1Sp9++qkGDRoku92ud955R+3atdOGDRsc14gdOXJEt9xyiyMclS9fXosWLVLfvn2VmpqqwYMHO+3z//7v/+Tt7a3nn39e6enp8vb2zlUtV9OlSxdt375dzz77rMLDw3X06FEtXbpUBw4cUHh4uCTpww8/VM+ePRUdHa3x48fr3Llzmjp1qlq3bq3Nmzc7+kkXZ/Cio6PVunVrvfnmmypVqlS+a8QNzgC4phkzZhhJ5qeffjJ79uwxXl5eZtCgQY7td9xxh6lXr55jPSkpyUgyM2bMyLYvSWbUqFGO9VGjRhlJpn///o62jIwMU6lSJWOz2Ux8fLyj/dSpU6ZkyZKmZ8+ejraEhAQjydx0000mNTXV0f7ZZ58ZSeaf//ynMcaYrKwsU6NGDRMdHW2ysrIc/c6dO2eqVq1q7r777mw1devWLVfvz+DBg40k8/333zvazpw5Y6pWrWrCw8NNZmam0/gHDBhwzX1eeg/9/PzM0aNHnbZlZGSY9PR0p7ZTp06ZChUqmD59+jjajh07lu39vnyMfyfJeHt7m927dzvafvnlFyPJTJ482dHWsWNHU6pUKfPHH3842nbt2mW8vLyc9vn2228bSebYsWPXHO/lJBlJZuPGjY62/fv3Gx8fH3P//fc72vr27WsqVqxojh8/7vT6rl27Gn9/f3Pu3DljzP9+TqpVq+Zou5pL/RMSEpzaL//ZPnXqlJFk3njjjSvu68yZMyYgIMD069fPqT05Odn4+/s7tffs2dNIMiNGjLhmjUBucRoLcFG1atX02GOPafr06Tp8+LDb9vvEE084/u3p6anmzZvLGKO+ffs62gMCAlSrVi3t3bs32+sff/xx+fr6OtYffPBBVaxYUd9++60kKTExUbt27dKjjz6qEydO6Pjx4zp+/LjOnj2rtm3bavXq1dmu33jqqadyVfu3336rFi1aOJ3qKlOmjPr37699+/bp119/zd2bkIMuXbpkmzHx9PR0zEhkZWXp5MmTysjIUPPmzfXzzz/n+ViSFBUVpYiICMd6w4YN5efn53jPMzMztWzZMnXu3NlpZq969eqKiYlx2tela5O++uqrPF0b07JlSzVr1syxXqVKFXXq1ElLlixRZmamjDH68ssv1bFjRxljHJ/p8ePHFR0drZSUlGzvR8+ePR0zfe5QsmRJeXt7a+XKlTp16lSOfZYuXarTp0+rW7duTjV6enoqMjLS6fTjJU8//bTbagQIO0AejBw5UhkZGW69M6tKlSpO6/7+/vLx8VG5cuWytef0R6VGjRpO6zabTdWrV3dcN7Fr1y5JF//YlS9f3ml57733lJ6erpSUFKd9VK1aNVe179+/X7Vq1crWXqdOHcf2vLpSDbNmzVLDhg3l4+OjoKAglS9fXgsXLsw2Bldd/jlIUtmyZR3v+dGjR/Xnn3+qevXq2fpd3vbII4+oVatWeuKJJ1ShQgV17dpVn332Wa6Dz+WfqSTVrFlT586d07Fjx3Ts2DGdPn1a06dPz/aZ9u7d21Hv3+X2M80tu92u8ePHa9GiRapQoYJuv/12vf7660pOTnb0ufSzd9ddd2Wr87vvvstWo5eXlypVquTWOnFj45odIA+qVaumHj16aPr06RoxYkS27Ve68DYzM/OK+/T09MxVm6SrXj9zJZf+wL7xxhtq3Lhxjn3KlCnjtO7OGYC8yqmGjz76SL169VLnzp31wgsvKDg4WJ6enoqLi9OePXvydTx3vuclS5bU6tWrlZCQoIULF2rx4sX69NNPddddd+m777674rFy69Jn2qNHD/Xs2TPHPpdfo5Tbz9SVn+HBgwerY8eOmj9/vpYsWaJXXnlFcXFxWrFihZo0aeKo88MPP1RISEi213t5Of8pstvt8vDg/8XhPoQdII9Gjhypjz76SOPHj8+2rWzZspKk06dPO7XnZ4bjWi793/Mlxhjt3r3b8cfu0qkZPz8/RUVFufXYYWFh2rFjR7b233//3bHdnb744gtVq1ZNc+fOdfqjPGrUKKd+BfGE5ODgYPn4+Gj37t3ZtuXU5uHhobZt26pt27aaMGGCxo0bp5dfflkJCQnX/Bwu/0wlaefOnSpVqpTj1J6vr68yMzPd/pm6+jMcERGhYcOGadiwYdq1a5caN26st956Sx999JHjZy84ONjtdQK5QXQG8igiIkI9evTQv//9b6cpe+lioChXrly224TfeeedAqvnP//5j86cOeNY/+KLL3T48GHHdSTNmjVTRESE3nzzTaWlpWV7/bFjx/J87Pbt22vDhg1au3ato+3s2bOaPn26wsPDVbdu3TzvOyeXZkT+Ptuyfv16p+NLctzFc/kf7PweOyoqSvPnz3d63tLu3bu1aNEip74nT57M9vpLs2rp6enXPNbatWudrrk5ePCgvvrqK91zzz3y9PSUp6enunTpoi+//FLbtm3L9vr8fKZhYWHy9PS85s/wuXPn9Ndffzm1RUREyNfX1zHG6Oho+fn5ady4cbpw4YJb6wRyg5kdIB9efvllffjhh9qxY4fq1avntO2JJ55QfHy8nnjiCTVv3lyrV6/Wzp07C6yWwMBAtW7dWr1799aRI0c0ceJEVa9eXf369ZN0cYbhvffeU0xMjOrVq6fevXvrpptu0h9//KGEhAT5+fnpm2++ydOxR4wYoU8++UQxMTEaNGiQAgMDNWvWLCUlJenLL790+ymJe++9V3PnztX999+vDh06KCkpSdOmTVPdunWdglzJkiVVt25dffrpp6pZs6YCAwNVv379fH+1x+jRo/Xdd9+pVatWevrpp5WZmal//etfql+/vhITEx39xo4dq9WrV6tDhw4KCwvT0aNH9c4776hSpUrXfG6RJNWvX1/R0dFOt55LF58bdEl8fLwSEhIUGRmpfv36qW7dujp58qR+/vlnLVu2LMfAlRv+/v566KGHNHnyZNlsNkVERGjBggXZrq/ZuXOn2rZtq4cfflh169aVl5eX5s2bpyNHjqhr166SLob/qVOn6rHHHlPTpk3VtWtXlS9fXgcOHNDChQvVqlUr/etf/8pTnUCuFOKdYECx8fdbzy936VbZv996bszFW7r79u1r/P39ja+vr3n44YfN0aNHr3jr+eW3J/fs2dOULl062/Euv8390i3Cn3zyiYmNjTXBwcGmZMmSpkOHDmb//v3ZXr9582bzwAMPmKCgIGO3201YWJh5+OGHzfLly69Z09Xs2bPHPPjggyYgIMD4+PiYFi1amAULFmTrJxdvPc/pluasrCwzbtw4ExYWZux2u2nSpIlZsGCB6dmzpwkLC3Pq++OPP5pmzZoZb29vp/f+Sree51RbWFiY0+3+xhizfPly06RJE+Pt7W0iIiLMe++9Z4YNG2Z8fHyc+nTq1MmEhoYab29vExoaarp162Z27tx5zfFfquWjjz4yNWrUcIzz8lvBjTHmyJEjZsCAAaZy5cqmRIkSJiQkxLRt29ZMnz7d0efSz8nnn39+zWNfcuzYMdOlSxdTqlQpU7ZsWfPkk0+abdu2Od16fvz4cTNgwABTu3ZtU7p0aePv728iIyPNZ599lm1/CQkJJjo62vj7+xsfHx8TERFhevXq5XR7/ZV+7oH8sBmTh6vuAADZdO7cWdu3b8/xWhtX2Ww2DRgwgBkPwA24ZgcA8uDyLxHdtWuXvv32W7Vp06ZwCgJwRVyzAwB5UK1aNfXq1UvVqlXT/v37NXXqVHl7e+vFF18s7NIAXIawAwB50K5dO33yySdKTk6W3W5Xy5YtNW7cuBwfBAigcHHNDgAAsDSu2QEAAJZG2AEAAJbGNTu6+P0yhw4dkq+vb4E8Xh4AALifMUZnzpxRaGjoVR9eStiRdOjQIVWuXLmwywAAAHlw8OBBVapU6YrbCTu6+EV60sU3y8/Pr5CrAQAAuZGamqrKlSs7/o5fCWFH//tmZD8/P8IOAADFzLUuQeECZQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmFGnZWr16tjh07KjQ0VDabTfPnz3fabrPZclzeeOMNR5/w8PBs2+Pj46/zSAAAQFFVqGHn7NmzatSokaZMmZLj9sOHDzstH3zwgWw2m7p06eLUb+zYsU79nn322etRPgAAKAYK9dbzmJgYxcTEXHF7SEiI0/pXX32lO++8U9WqVXNq9/X1zdYXAABAKkbX7Bw5ckQLFy5U3759s22Lj49XUFCQmjRpojfeeEMZGRmFUCEAACiKis1DBWfNmiVfX1898MADTu2DBg1S06ZNFRgYqB9//FGxsbE6fPiwJkyYcMV9paenKz093bGemppaYHUDAIDCVWzCzgcffKDu3bvLx8fHqX3o0KGOfzds2FDe3t568sknFRcXJ7vdnuO+4uLiNGbMmAKtFwAAFA3F4jTW999/rx07duiJJ564Zt/IyEhlZGRo3759V+wTGxurlJQUx3Lw4EE3VgsAAIqSYjGz8/7776tZs2Zq1KjRNfsmJibKw8NDwcHBV+xjt9uvOOsDAACspVDDTlpamnbv3u1YT0pKUmJiogIDA1WlShVJF6+n+fzzz/XWW29le/3atWu1fv163XnnnfL19dXatWs1ZMgQ9ejRQ2XLlr1u4wAAAEVXoYadjRs36s4773SsX7r+pmfPnpo5c6Ykac6cOTLGqFu3btleb7fbNWfOHI0ePVrp6emqWrWqhgwZ4nQdDwAAuLHZjDGmsIsobKmpqfL391dKSor8/PwKuxwAAJALuf37XSyu2SnOwkcszNa2L75DIVQCAMCNqVjcjQUAAJBXhB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphRp2Vq9erY4dOyo0NFQ2m03z58932t6rVy/ZbDanpV27dk59Tp48qe7du8vPz08BAQHq27ev0tLSruMoAABAUVaoYefs2bNq1KiRpkyZcsU+7dq10+HDhx3LJ5984rS9e/fu2r59u5YuXaoFCxZo9erV6t+/f0GXDgAAigmvwjx4TEyMYmJirtrHbrcrJCQkx22//fabFi9erJ9++knNmzeXJE2ePFnt27fXm2++qdDQULfXDAAAipcif83OypUrFRwcrFq1aunpp5/WiRMnHNvWrl2rgIAAR9CRpKioKHl4eGj9+vWFUS4AAChiCnVm51ratWunBx54QFWrVtWePXv00ksvKSYmRmvXrpWnp6eSk5MVHBzs9BovLy8FBgYqOTn5ivtNT09Xenq6Yz01NbXAxgAAAApXkQ47Xbt2dfy7QYMGatiwoSIiIrRy5Uq1bds2z/uNi4vTmDFj3FEiAAAo4or8aay/q1atmsqVK6fdu3dLkkJCQnT06FGnPhkZGTp58uQVr/ORpNjYWKWkpDiWgwcPFmjdAACg8BSrsPPf//5XJ06cUMWKFSVJLVu21OnTp7Vp0yZHnxUrVigrK0uRkZFX3I/dbpefn5/TAgAArKlQT2OlpaU5ZmkkKSkpSYmJiQoMDFRgYKDGjBmjLl26KCQkRHv27NGLL76o6tWrKzo6WpJUp04dtWvXTv369dO0adN04cIFDRw4UF27duVOLAAAIKmQZ3Y2btyoJk2aqEmTJpKkoUOHqkmTJnr11Vfl6empLVu26L777lPNmjXVt29fNWvWTN9//73sdrtjH7Nnz1bt2rXVtm1btW/fXq1bt9b06dMLa0gAAKCIKdSZnTZt2sgYc8XtS5YsueY+AgMD9fHHH7uzLAAAYCHF6podAAAAVxF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRVq2Fm9erU6duyo0NBQ2Ww2zZ8/37HtwoULGj58uBo0aKDSpUsrNDRUjz/+uA4dOuS0j/DwcNlsNqclPj7+Oo8EAAAUVYUads6ePatGjRppypQp2badO3dOP//8s1555RX9/PPPmjt3rnbs2KH77rsvW9+xY8fq8OHDjuXZZ5+9HuUDAIBiwKswDx4TE6OYmJgct/n7+2vp0qVObf/617/UokULHThwQFWqVHG0+/r6KiQkpEBrBQAAxVOxumYnJSVFNptNAQEBTu3x8fEKCgpSkyZN9MYbbygjI+Oq+0lPT1dqaqrTAgAArKlQZ3Zc8ddff2n48OHq1q2b/Pz8HO2DBg1S06ZNFRgYqB9//FGxsbE6fPiwJkyYcMV9xcXFacyYMdejbAAAUMiKRdi5cOGCHn74YRljNHXqVKdtQ4cOdfy7YcOG8vb21pNPPqm4uDjZ7fYc9xcbG+v0utTUVFWuXLlgigcAAIWqyIedS0Fn//79WrFihdOsTk4iIyOVkZGhffv2qVatWjn2sdvtVwxCAADAWop02LkUdHbt2qWEhAQFBQVd8zWJiYny8PBQcHDwdagQAAAUdYUadtLS0rR7927HelJSkhITExUYGKiKFSvqwQcf1M8//6wFCxYoMzNTycnJkqTAwEB5e3tr7dq1Wr9+ve688075+vpq7dq1GjJkiHr06KGyZcsW1rAAAEARUqhhZ+PGjbrzzjsd65euo+nZs6dGjx6tr7/+WpLUuHFjp9clJCSoTZs2stvtmjNnjkaPHq309HRVrVpVQ4YMcboeBwAA3NgKNey0adNGxpgrbr/aNklq2rSp1q1b5+6yAACAhRSr5+wAAAC4irADAAAsjbADAAAsjbADAAAsjbADAAAsjbADAAAsjbADAAAsjbADAAAszeWwc/DgQf33v/91rG/YsEGDBw/W9OnT3VoYAACAO7gcdh599FElJCRIkpKTk3X33Xdrw4YNevnllzV27Fi3FwgAAJAfLoedbdu2qUWLFpKkzz77TPXr19ePP/6o2bNna+bMme6uDwAAIF9cDjsXLlyQ3W6XJC1btkz33XefJKl27do6fPiwe6sDAADIJ5fDTr169TRt2jR9//33Wrp0qdq1aydJOnTokIKCgtxeIAAAQH64HHbGjx+vf//732rTpo26deumRo0aSZK+/vprx+ktAACAosLLlc7GGFWrVk0HDhxQRkaGypYt69jWv39/lSpVyu0FAgAA5IdLMzvGGFWvXl3JyclOQUeSwsPDFRwc7NbiAAAA8sulsOPh4aEaNWroxIkTBVUPAACAW7l8zU58fLxeeOEFbdu2rSDqAQAAcCuXrtmRpMcff1znzp1To0aN5O3trZIlSzptP3nypNuKAwAAyC+Xw87EiRMLoAwAAICC4XLY6dmzZ0HUAQAAUCDy9K3ne/bs0ciRI9WtWzcdPXpUkrRo0SJt377drcUBAADkl8thZ9WqVWrQoIHWr1+vuXPnKi0tTZL0yy+/aNSoUW4vEAAAID9cDjsjRozQa6+9pqVLl8rb29vRftddd2ndunVuLQ4AACC/XA47W7du1f3335+tPTg4WMePH3dLUQAAAO7ictgJCAjI8dvNN2/erJtuusktRQEAALiLy2Gna9euGj58uJKTk2Wz2ZSVlaU1a9bo+eef1+OPP14QNQIAAOSZy2Fn3Lhxql27tipXrqy0tDTVrVtXt99+u2699VaNHDmyIGoEAADIM5efs+Pt7a13331Xr776qrZu3aq0tDQ1adJENWrUKIj6AAAA8sXlsHNJ5cqVVblyZWVmZmrr1q06depUtm9CBwAAKGwun8YaPHiw3n//fUlSZmam7rjjDjVt2lSVK1fWypUr3V0fAABAvrgcdr744gs1atRIkvTNN99o7969+v333zVkyBC9/PLLbi8QAAAgP1wOO8ePH1dISIgk6dtvv9XDDz+smjVrqk+fPtq6davbCwQAAMgPl8NOhQoV9OuvvyozM1OLFy/W3XffLUk6d+6cPD093V4gAABAfrh8gXLv3r318MMPq2LFirLZbIqKipIkrV+/XrVr13Z7gQAAAPnhctgZPXq06tevr4MHD+qhhx6S3W6XJHl6emrEiBFuLxAAACA/8nTr+YMPPpitrWfPnvkuBgAAwN1cDjtjx4696vZXX301z8UAAAC4m8thZ968eU7rFy5cUFJSkry8vBQREUHYAQAARYrLYWfz5s3Z2lJTU9WrVy/df//9bikKAADAXVy+9Twnfn5+GjNmjF555RWXXrd69Wp17NhRoaGhstlsmj9/vtN2Y4xeffVVVaxYUSVLllRUVJR27drl1OfkyZPq3r27/Pz8FBAQoL59+yotLS2/QwIAABbhlrAjSSkpKUpJSXHpNWfPnlWjRo00ZcqUHLe//vrrmjRpkqZNm6b169erdOnSio6O1l9//eXo0717d23fvl1Lly7VggULtHr1avXv3z9fYwEAANbh8mmsSZMmOa0bY3T48GF9+OGHiomJcWlfMTExV3yNMUYTJ07UyJEj1alTJ0nSf/7zH1WoUEHz589X165d9dtvv2nx4sX66aef1Lx5c0nS5MmT1b59e7355psKDQ11dXgAAMBiXA47b7/9ttO6h4eHypcvr549eyo2NtZthSUlJSk5Odnx0EJJ8vf3V2RkpNauXauuXbtq7dq1CggIcAQdSYqKipKHh4fWr19/xWuI0tPTlZ6e7lhPTU11W90AAKBocTnsJCUlFUQd2SQnJ0u6+PUUf1ehQgXHtuTkZAUHBztt9/LyUmBgoKNPTuLi4jRmzBg3VwwAAIoit12zU5zExsY6rjFKSUnRwYMHC7skAABQQIps2Ln0zepHjhxxaj9y5IhjW0hIiI4ePeq0PSMjQydPnnT0yYndbpefn5/TAgAArKnIhp2qVasqJCREy5cvd7SlpqZq/fr1atmypSSpZcuWOn36tDZt2uTos2LFCmVlZSkyMvK61wwAAIqePH03lrukpaVp9+7djvWkpCQlJiYqMDBQVapU0eDBg/Xaa6+pRo0aqlq1ql555RWFhoaqc+fOkqQ6deqoXbt26tevn6ZNm6YLFy5o4MCB6tq1K3diAQAASbmc2WnatKlOnTol6eJ3Y507d84tB9+4caOaNGmiJk2aSJKGDh2qJk2aOL5y4sUXX9Szzz6r/v376+abb1ZaWpoWL14sHx8fxz5mz56t2rVrq23btmrfvr1at26t6dOnu6U+AABQ/NmMMeZanUqWLKldu3apUqVK8vT01OHDh7PdBVWcpaamyt/fXykpKW6/fid8xMJsbfviO7j1GAAA3Ihy+/c7V6exGjdurN69e6t169YyxujNN99UmTJlcuzLF4ECAICiJFdhZ+bMmRo1apQWLFggm82mRYsWycsr+0ttNhthBwAAFCm5Cju1atXSnDlzJF18YvLy5cstdRoLAABYl8t3Y2VlZRVEHQAAAAUiT7ee79mzRxMnTtRvv/0mSapbt66ee+45RUREuLU4AACA/HL5oYJLlixR3bp1tWHDBjVs2FANGzbU+vXrVa9ePS1durQgagQAAMgzl2d2RowYoSFDhig+Pj5b+/Dhw3X33Xe7rTgAAID8cnlm57ffflPfvn2ztffp00e//vqrW4oCAABwF5fDTvny5ZWYmJitPTExkTu0AABAkePyaax+/fqpf//+2rt3r2699VZJ0po1azR+/HgNHTrU7QUCAADkh8th55VXXpGvr6/eeustxcbGSpJCQ0M1evRoDRo0yO0FAgAA5IfLYcdms2nIkCEaMmSIzpw5I0ny9fV1e2EAAADukKfn7FxCyAEAAEWdyxcoAwAAFCeEHQAAYGmEHQAAYGkuhZ0LFy6obdu22rVrV0HVAwAA4FYuhZ0SJUpoy5YtBVULAACA27l8GqtHjx56//33C6IWAAAAt3P51vOMjAx98MEHWrZsmZo1a6bSpUs7bZ8wYYLbigMAAMgvl8POtm3b1LRpU0nSzp07nbbZbDb3VAUAAOAmLoedhISEgqgDAACgQOT51vPdu3dryZIl+vPPPyVJxhi3FQUAAOAuLoedEydOqG3btqpZs6bat2+vw4cPS5L69u2rYcOGub1AAACA/HA57AwZMkQlSpTQgQMHVKpUKUf7I488osWLF7u1OAAAgPxy+Zqd7777TkuWLFGlSpWc2mvUqKH9+/e7rTAAAAB3cHlm5+zZs04zOpecPHlSdrvdLUUBAAC4i8th57bbbtN//vMfx7rNZlNWVpZef/113XnnnW4tDgAAIL9cPo31+uuvq23bttq4caPOnz+vF198Udu3b9fJkye1Zs2agqgRAAAgz1ye2alfv7527typ1q1bq1OnTjp79qweeOABbd68WREREQVRIwAAQJ7ZDA/IUWpqqvz9/ZWSkiI/Pz+37jt8xMJr9tkX38GtxwQA4EaQ27/fLp/GkqRTp07p/fff12+//SZJqlu3rnr37q3AwMC8VQsAAFBAXD6NtXr1aoWHh2vSpEk6deqUTp06pUmTJqlq1apavXp1QdQIAACQZy7P7AwYMECPPPKIpk6dKk9PT0lSZmamnnnmGQ0YMEBbt251e5EAAAB55fLMzu7duzVs2DBH0JEkT09PDR06VLt373ZrcQAAAPnlcthp2rSp41qdv/vtt9/UqFEjtxQFAADgLrk6jbVlyxbHvwcNGqTnnntOu3fv1i233CJJWrdunaZMmaL4+PiCqRIAACCPcnXruYeHh2w2m67V1WazKTMz023FXS/ceg4AQPHj1lvPk5KS3FYYAADA9ZSrsBMWFlbQdQAAABSIPD1U8NChQ/rhhx909OhRZWVlOW0bNGiQWwq7JDw8XPv378/W/swzz2jKlClq06aNVq1a5bTtySef1LRp09xaBwAAKJ5cDjszZ87Uk08+KW9vbwUFBclmszm22Ww2t4edn376yek6oG3btunuu+/WQw895Gjr16+fxo4d61gvVaqUW2sAAADFl8th55VXXtGrr76q2NhYeXi4fOe6y8qXL++0Hh8fr4iICN1xxx2OtlKlSikkJKTAawEAAMWPy2nl3Llz6tq163UJOpc7f/68PvroI/Xp08dpRmn27NkqV66c6tevr9jYWJ07d+6q+0lPT1dqaqrTAgAArMnlxNK3b199/vnnBVHLNc2fP1+nT59Wr169HG2PPvqoPvroIyUkJCg2NlYffvihevTocdX9xMXFyd/f37FUrly5gCsHAACFJVfP2fm7zMxM3Xvvvfrzzz/VoEEDlShRwmn7hAkT3Frg30VHR8vb21vffPPNFfusWLFCbdu21e7duxUREZFjn/T0dKWnpzvWU1NTVblyZZ6zAwBAMeLW5+z8XVxcnJYsWaJatWpJUrYLlAvK/v37tWzZMs2dO/eq/SIjIyXpqmHHbrfLbre7vUYAAFD0uBx23nrrLX3wwQdOp5KuhxkzZig4OFgdOlx9FiQxMVGSVLFixetQFQAAKOpcDjt2u12tWrUqiFquKCsrSzNmzFDPnj3l5fW/kvfs2aOPP/5Y7du3V1BQkLZs2aIhQ4bo9ttvV8OGDa9rjQAAoGhy+QLl5557TpMnTy6IWq5o2bJlOnDggPr06ePU7u3trWXLlumee+5R7dq1NWzYMHXp0uWq1/QAAIAbi8szOxs2bNCKFSu0YMEC1atXL9sFyte6piYv7rnnnhy/hLRy5crZnp4MAADwdy6HnYCAAD3wwAMFUQsAAIDbuRx2ZsyYURB1AAAAFIjr/xhkAACA68jlmZ2qVate9Xk6e/fuzVdBAAAA7uRy2Bk8eLDT+oULF7R582YtXrxYL7zwgrvqAgAAcAuXw85zzz2XY/uUKVO0cePGfBcEAADgTm67ZicmJkZffvmlu3YHAADgFm4LO1988YUCAwPdtTsAAAC3cPk0VpMmTZwuUDbGKDk5WceOHdM777zj1uIAAADyy+Ww07lzZ6d1Dw8PlS9fXm3atFHt2rXdVRcAAIBbuBx2Ro0aVRB1AAAAFAgeKggAACwt1zM7Hh4eV32YoCTZbDZlZGTkuygAAAB3yXXYmTdv3hW3rV27VpMmTVJWVpZbigIAAHCXXIedTp06ZWvbsWOHRowYoW+++Ubdu3fX2LFj3VocAABAfuXpmp1Dhw6pX79+atCggTIyMpSYmKhZs2YpLCzM3fUBAADki0thJyUlRcOHD1f16tW1fft2LV++XN98843q169fUPUBAADkS65PY73++usaP368QkJC9Mknn+R4WgsAAKCosRljTG46enh4qGTJkoqKipKnp+cV+82dO9dtxV0vqamp8vf3V0pKivz8/Ny67/ARC6/ZZ198B7ceEwCAG0Fu/37nembn8ccfv+at5wAAAEVNrsPOzJkzC7AMAACAgsETlAEAgKURdgAAgKURdgAAgKURdgAAgKURdgAAgKXl+m4sFJycnsXDs3cAAHAPZnYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClcTdWEXX5HVrcnQUAQN4wswMAACyNsAMAACyNsAMAACyNsAMAACyNsAMAACyNsAMAACyNsAMAACytSIed0aNHy2azOS21a9d2bP/rr780YMAABQUFqUyZMurSpYuOHDlSiBUDAICipkiHHUmqV6+eDh8+7Fh++OEHx7YhQ4bom2++0eeff65Vq1bp0KFDeuCBBwqxWgAAUNQU+Scoe3l5KSQkJFt7SkqK3n//fX388ce66667JEkzZsxQnTp1tG7dOt1yyy3Xu1QAAFAEFfmZnV27dik0NFTVqlVT9+7ddeDAAUnSpk2bdOHCBUVFRTn61q5dW1WqVNHatWuvus/09HSlpqY6LQAAwJqKdNiJjIzUzJkztXjxYk2dOlVJSUm67bbbdObMGSUnJ8vb21sBAQFOr6lQoYKSk5Ovut+4uDj5+/s7lsqVKxfgKAAAQGEq0qexYmJiHP9u2LChIiMjFRYWps8++0wlS5bM835jY2M1dOhQx3pqaiqBBwAAiyrSMzuXCwgIUM2aNbV7926FhITo/PnzOn36tFOfI0eO5HiNz9/Z7Xb5+fk5LQAAwJqKVdhJS0vTnj17VLFiRTVr1kwlSpTQ8uXLHdt37NihAwcOqGXLloVYJQAAKEqK9Gms559/Xh07dlRYWJgOHTqkUaNGydPTU926dZO/v7/69u2roUOHKjAwUH5+fnr22WfVsmXLG+ZOrPARC53W98V3KKRKAAAouop02Pnvf/+rbt266cSJEypfvrxat26tdevWqXz58pKkt99+Wx4eHurSpYvS09MVHR2td955p5CrBgAARUmRDjtz5sy56nYfHx9NmTJFU6ZMuU4VAQCA4qZIhx38z+WnrAAAQO4UqwuUAQAAXEXYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAluZV2AXAfcJHLMzWti++QyFUAgBA0cHMDgAAsDTCDgAAsDTCDgAAsDSu2bG4y6/j4RoeAMCNhpkdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaUU67MTFxenmm2+Wr6+vgoOD1blzZ+3YscOpT5s2bWSz2ZyWp556qpAqBgAARU2RDjurVq3SgAEDtG7dOi1dulQXLlzQPffco7Nnzzr169evnw4fPuxYXn/99UKqGAAAFDVF+gnKixcvdlqfOXOmgoODtWnTJt1+++2O9lKlSikkJOR6lwcAAIqBIj2zc7mUlBRJUmBgoFP77NmzVa5cOdWvX1+xsbE6d+5cYZQHAACKoCI9s/N3WVlZGjx4sFq1aqX69es72h999FGFhYUpNDRUW7Zs0fDhw7Vjxw7NnTv3ivtKT09Xenq6Yz01NbVAawcAAIWn2ISdAQMGaNu2bfrhhx+c2vv37+/4d4MGDVSxYkW1bdtWe/bsUURERI77iouL05gxYwq0XqvhC0UBAMVVsTiNNXDgQC1YsEAJCQmqVKnSVftGRkZKknbv3n3FPrGxsUpJSXEsBw8edGu9AACg6CjSMzvGGD377LOaN2+eVq5cqapVq17zNYmJiZKkihUrXrGP3W6X3W53V5kAAKAIK9JhZ8CAAfr444/11VdfydfXV8nJyZIkf39/lSxZUnv27NHHH3+s9u3bKygoSFu2bNGQIUN0++23q2HDhoVcPQAAKAqKdNiZOnWqpIsPDvy7GTNmqFevXvL29tayZcs0ceJEnT17VpUrV1aXLl00cuTIQqj2xnL5NTwS1/EAAIqmIh12jDFX3V65cmWtWrXqOlUDAACKo2JxgTIAAEBeEXYAAIClFenTWLgx8UwfAIA7MbMDAAAsjZmdGwx3UQEAbjTM7AAAAEtjZgfZ5DT74679MIsEALjemNkBAACWxswOCpW7ZpEAALgSZnYAAIClEXYAAIClEXYAAIClcc0Oijzu6gIA5AczOwAAwNIIOwAAwNIIOwAAwNK4Zgduk5tn5hTU05m5hgcAcCXM7AAAAEtjZgc3DO7qAoAbEzM7AADA0pjZwQ39/VRc+wMA1sfMDgAAsDRmdgAL4vokAPgfZnYAAIClMbMDXENeruvJzXVQzLQAwPXBzA4AALA0ZnZgCcXxjjKuqwGA64OZHQAAYGnM7AB/k9cZouI4swQANwpmdgAAgKUxswO4iFkcAChemNkBAACWxswOUMzk9S4uvgcMwI2KmR0AAGBpzOwAcHDXk58LahaJZxMByAtmdgAAgKURdgAAgKVxGgsoQvJ6+qcwb4cvjrficzoMuLEwswMAACyNmR2gCCuKsyZ5qak4zKRwaz5gXZaZ2ZkyZYrCw8Pl4+OjyMhIbdiwobBLAgAARYAlZnY+/fRTDR06VNOmTVNkZKQmTpyo6Oho7dixQ8HBwYVdHlAkFcVZo7zIzYxMYc5GFfaslrseJwAUZ5aY2ZkwYYL69eun3r17q27dupo2bZpKlSqlDz74oLBLAwAAhazYz+ycP39emzZtUmxsrKPNw8NDUVFRWrt2bSFWBuBqrueMjLvwsMT/4WtLrq6wP9OidvzC/pyLfdg5fvy4MjMzVaFCBaf2ChUq6Pfff8/xNenp6UpPT3esp6SkSJJSU1PdXl9W+jm37xOwopz++yvq//3k5ndGTmO4/HW56ZNXuXkP83KsvNZ8+esK4vduUVCQn2lxPH5BHfvSfo0xV+9oirk//vjDSDI//vijU/sLL7xgWrRokeNrRo0aZSSxsLCwsLCwWGA5ePDgVbNCsZ/ZKVeunDw9PXXkyBGn9iNHjigkJCTH18TGxmro0KGO9aysLJ08eVJBQUGy2WxXPFZqaqoqV66sgwcPys/Pzz0DKCZu1LHfqOOWGDtjZ+w3kuI6dmOMzpw5o9DQ0Kv2K/Zhx9vbW82aNdPy5cvVuXNnSRfDy/LlyzVw4MAcX2O322W3253aAgICcn1MPz+/YvXD4E436thv1HFLjJ2x33gYe/Eau7+//zX7FPuwI0lDhw5Vz5491bx5c7Vo0UITJ07U2bNn1bt378IuDQAAFDJLhJ1HHnlEx44d06uvvqrk5GQ1btxYixcvznbRMgAAuPFYIuxI0sCBA6942spd7Ha7Ro0ale0U2I3gRh37jTpuibEzdsZ+I7H62G3GXOt+LQAAgOLLEk9QBgAAuBLCDgAAsDTCDgAAsDTCDgAAsDTCTi5NmTJF4eHh8vHxUWRkpDZs2FDYJeXb6tWr1bFjR4WGhspms2n+/PlO240xevXVV1WxYkWVLFlSUVFR2rVrl1OfkydPqnv37vLz81NAQID69u2rtLS06zgK18XFxenmm2+Wr6+vgoOD1blzZ+3YscOpz19//aUBAwYoKChIZcqUUZcuXbI9pfvAgQPq0KGDSpUqpeDgYL3wwgvKyMi4nkNx2dSpU9WwYUPHg8NatmypRYsWObZbddw5iY+Pl81m0+DBgx1tVh3/6NGjZbPZnJbatWs7tlt13Jf88ccf6tGjh4KCglSyZEk1aNBAGzdudGy36u+68PDwbJ+7zWbTgAEDJFn/c3fiju+nsro5c+YYb29v88EHH5jt27ebfv36mYCAAHPkyJHCLi1fvv32W/Pyyy+buXPnGklm3rx5Ttvj4+ONv7+/mT9/vvnll1/MfffdZ6pWrWr+/PNPR5927dqZRo0amXXr1pnvv//eVK9e3XTr1u06j8Q10dHRZsaMGWbbtm0mMTHRtG/f3lSpUsWkpaU5+jz11FOmcuXKZvny5Wbjxo3mlltuMbfeeqtje0ZGhqlfv76JiooymzdvNt9++60pV66ciY2NLYwh5drXX39tFi5caHbu3Gl27NhhXnrpJVOiRAmzbds2Y4x1x325DRs2mPDwcNOwYUPz3HPPOdqtOv5Ro0aZevXqmcOHDzuWY8eOObZbddzGGHPy5EkTFhZmevXqZdavX2/27t1rlixZYnbv3u3oY9XfdUePHnX6zJcuXWokmYSEBGOMtT/3yxF2cqFFixZmwIABjvXMzEwTGhpq4uLiCrEq97o87GRlZZmQkBDzxhtvONpOnz5t7Ha7+eSTT4wxxvz6669Gkvnpp58cfRYtWmRsNpv5448/rlvt+XX06FEjyaxatcoYc3GcJUqUMJ9//rmjz2+//WYkmbVr1xpjLgZFDw8Pk5yc7OgzdepU4+fnZ9LT06/vAPKpbNmy5r333rthxn3mzBlTo0YNs3TpUnPHHXc4wo6Vxz9q1CjTqFGjHLdZedzGGDN8+HDTunXrK26/kX7XPffccyYiIsJkZWVZ/nO/HKexruH8+fPatGmToqKiHG0eHh6KiorS2rVrC7GygpWUlKTk5GSncfv7+ysyMtIx7rVr1yogIEDNmzd39ImKipKHh4fWr19/3WvOq5SUFElSYGCgJGnTpk26cOGC09hr166tKlWqOI29QYMGTk/pjo6OVmpqqrZv334dq8+7zMxMzZkzR2fPnlXLli1vmHEPGDBAHTp0cBqnZP3PfdeuXQoNDVW1atXUvXt3HThwQJL1x/3111+refPmeuihhxQcHKwmTZro3XffdWy/UX7XnT9/Xh999JH69Okjm81m+c/9coSdazh+/LgyMzOzffVEhQoVlJycXEhVFbxLY7vauJOTkxUcHOy03cvLS4GBgcXmvcnKytLgwYPVqlUr1a9fX9LFcXl7e2f7ctjLx57Te3NpW1G2detWlSlTRna7XU899ZTmzZununXrWn7ckjRnzhz9/PPPiouLy7bNyuOPjIzUzJkztXjxYk2dOlVJSUm67bbbdObMGUuPW5L27t2rqVOnqkaNGlqyZImefvppDRo0SLNmzZJ04/yumz9/vk6fPq1evXpJsvbPe04s83URQF4MGDBA27Zt0w8//FDYpVw3tWrVUmJiolJSUvTFF1+oZ8+eWrVqVWGXVeAOHjyo5557TkuXLpWPj09hl3NdxcTEOP7dsGFDRUZGKiwsTJ999plKlixZiJUVvKysLDVv3lzjxo2TJDVp0kTbtm3TtGnT1LNnz0Ku7vp5//33FRMTo9DQ0MIupVAws3MN5cqVk6enZ7Yr1I8cOaKQkJBCqqrgXRrb1cYdEhKio0ePOm3PyMjQyZMni8V7M3DgQC1YsEAJCQmqVKmSoz0kJETnz5/X6dOnnfpfPvac3ptL24oyb29vVa9eXc2aNVNcXJwaNWqkf/7zn5Yf96ZNm3T06FE1bdpUXl5e8vLy0qpVqzRp0iR5eXmpQoUKlh7/3wUEBKhmzZravXu35T/3ihUrqm7duk5tderUcZzGuxF+1+3fv1/Lli3TE0884Wiz+ud+OcLONXh7e6tZs2Zavny5oy0rK0vLly9Xy5YtC7GyglW1alWFhIQ4jTs1NVXr1693jLtly5Y6ffq0Nm3a5OizYsUKZWVlKTIy8rrXnFvGGA0cOFDz5s3TihUrVLVqVaftzZo1U4kSJZzGvmPHDh04cMBp7Fu3bnX6Bbh06VL5+fll+8Va1GVlZSk9Pd3y427btq22bt2qxMREx9K8eXN1797d8W8rj//v0tLStGfPHlWsWNHyn3urVq2yPVpi586dCgsLk2Tt33WXzJgxQ8HBwerQoYOjzeqfezaFfYV0cTBnzhxjt9vNzJkzza+//mr69+9vAgICnK5QL47OnDljNm/ebDZv3mwkmQkTJpjNmzeb/fv3G2Mu3o4ZEBBgvvrqK7NlyxbTqVOnHG/HbNKkiVm/fr354YcfTI0aNYr87ZhPP/208ff3NytXrnS6LfPcuXOOPk899ZSpUqWKWbFihdm4caNp2bKladmypWP7pVsy77nnHpOYmGgWL15sypcvX+RvyRwxYoRZtWqVSUpKMlu2bDEjRowwNpvNfPfdd8YY6477Sv5+N5Yx1h3/sGHDzMqVK01SUpJZs2aNiYqKMuXKlTNHjx41xlh33MZcfMyAl5eX+cc//mF27dplZs+ebUqVKmU++ugjRx+r/q4z5uLdw1WqVDHDhw/Pts3Kn/vlCDu5NHnyZFOlShXj7e1tWrRoYdatW1fYJeVbQkKCkZRt6dmzpzHm4i2Zr7zyiqlQoYKx2+2mbdu2ZseOHU77OHHihOnWrZspU6aM8fPzM7179zZnzpwphNHkXk5jlmRmzJjh6PPnn3+aZ555xpQtW9aUKlXK3H///ebw4cNO+9m3b5+JiYkxJUuWNOXKlTPDhg0zFy5cuM6jcU2fPn1MWFiY8fb2NuXLlzdt27Z1BB1jrDvuK7k87Fh1/I888oipWLGi8fb2NjfddJN55JFHnJ4zY9VxX/LNN9+Y+vXrG7vdbmrXrm2mT5/utN2qv+uMMWbJkiVGUrbxGGP9z/3vbMYYUyhTSgAAANcB1+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAuC727dsnm82mxMTEwi7F4ffff9ctt9wiHx8fNW7c+LocMzw8XBMnTrwuxwJwEWEHuEH06tVLNptN8fHxTu3z58+XzWYrpKoK16hRo1S6dGnt2LHD6TuC3GHmzJkKCAjI1v7TTz+pf//+bj0WgKsj7AA3EB8fH40fP16nTp0q7FLc5vz583l+7Z49e9S6dWuFhYUpKCiowI8nSeXLl1epUqXytQ8AriHsADeQqKgohYSEKC4u7op9Ro8ene2UzsSJExUeHu5Y79Wrlzp37qxx48apQoUKCggI0NixY5WRkaEXXnhBgYGBqlSpkmbMmJFt/7///rtuvfVW+fj4qH79+lq1apXT9m3btikmJkZlypRRhQoV9Nhjj+n48eOO7W3atNHAgQM1ePBglStXTtHR0TmOIysrS2PHjlWlSpVkt9vVuHFjLV682LHdZrNp06ZNGjt2rGw2m0aPHp3jfq50vAkTJqhBgwYqXbq0KleurGeeeUZpaWmSpJUrV6p3795KSUmRzWZz2v/lp7FsNpvee+893X///SpVqpRq1Kihr7/+2qmGr7/+WjVq1JCPj4/uvPNOzZo1SzabTadPn5Yk7d+/Xx07dlTZsmVVunRp1atXT99++22O4wFuRIQd4Abi6empcePGafLkyfrvf/+br32tWLFChw4d0urVqzVhwgSNGjVK9957r8qWLav169frqaee0pNPPpntOC+88IKGDRumzZs3q2XLlurYsaNOnDghSTp9+rTuuusuNWnSRBs3btTixYt15MgRPfzww077mDVrlry9vbVmzRpNmzYtx/r++c9/6q233tKbb76pLVu2KDo6Wvfdd5927dolSTp8+LDq1aunYcOG6fDhw3r++eevONacjufh4aFJkyZp+/btmjVrllasWKEXX3xRknTrrbdq4sSJ8vPz0+HDh6+5/zFjxujhhx/Wli1b1L59e3Xv3l0nT56UJCUlJenBBx9U586d9csvv+jJJ5/Uyy+/7PT6AQMGKD09XatXr9bWrVs1fvx4lSlT5orHA244hf1NpACuj549e5pOnToZY4y55ZZbTJ8+fYwxxsybN8/8/VfBqFGjTKNGjZxe+/bbb5uwsDCnfYWFhZnMzExHW61atcxtt93mWM/IyDClS5c2n3zyiTHGmKSkJCPJxMfHO/pcuHDBVKpUyYwfP94YY8z//d//mXvuucfp2AcPHnT61uY77rjDNGnS5JrjDQ0NNf/4xz+c2m6++WbzzDPPONYbNWpkRo0addX95PZ4n3/+uQkKCnKsz5gxw/j7+2frFxYWZt5++23HuiQzcuRIx3paWpqRZBYtWmSMMWb48OGmfv36Tvt4+eWXjSRz6tQpY4wxDRo0MKNHj75mjcCNipkd4AY0fvx4zZo1S7/99lue91GvXj15ePzvV0iFChXUoEEDx7qnp6eCgoJ09OhRp9e1bNnS8W8vLy81b97cUccvv/yihIQElSlTxrHUrl1b0sXray5p1qzZVWtLTU3VoUOH1KpVK6f2Vq1a5WnMOR1v2bJlatu2rW666Sb5+vrqscce04kTJ3Tu3DmX99+wYUPHv0uXLi0/Pz/H+7Zjxw7dfPPNTv1btGjhtD5o0CC99tpratWqlUaNGqUtW7a4XANgZYQd4AZ0++23Kzo6WrGxsdm2eXh4yBjj1HbhwoVs/UqUKOG0brPZcmzLysrKdV1paWnq2LGjEhMTnZZdu3bp9ttvd/QrXbp0rvfpDpcfb9++fbr33nvVsGFDffnll9q0aZOmTJkiKW8XMOf3fXviiSe0d+9ePfbYY9q6dauaN2+uyZMnu1wHYFWEHeAGFR8fr2+++UZr1651ai9fvrySk5OdAo87n42zbt06x78zMjK0adMm1alTR5LUtGlTbd++XeHh4apevbrT4krA8fPzU2hoqNasWePUvmbNGtWtWzffY9i0aZOysrL01ltv6ZZbblHNmjV16NAhpz7e3t7KzMzM97Fq1aqljRs3OrX99NNP2fpVrlxZTz31lObOnathw4bp3XffzfexAasg7AA3qAYNGqh79+6aNGmSU3ubNm107Ngxvf7669qzZ4+mTJmiRYsWue24U6ZM0bx58/T7779rwIABOnXqlPr06SPp4oW2J0+eVLdu3fTTTz9pz549WrJkiXr37u1ycHjhhRc0fvx4ffrpp9qxY4dGjBihxMREPffcc/keQ/Xq1XXhwgVNnjxZe/fu1YcffpjtQunw8HClpaVp+fLlOn78eJ5Ob0nSk08+qd9//13Dhw/Xzp079dlnn2nmzJmS5Hg+0uDBg7VkyRIlJSXp559/VkJCgiNAAiDsADe0sWPHZjtdUqdOHb3zzjuaMmWKGjVqpA0bNlz1TiJXxcfHKz4+Xo0aNdIPP/ygr7/+WuXKlZMkx2xMZmam7rnnHjVo0ECDBw9WQECA0/VBuTFo0CANHTpUw4YNU4MGDbR48WLHLdz51ahRI02YMEHjx49X/fr1NXv27Gy3899666166qmn9Mgjj6h8+fJ6/fXX83SsqlWr6osvvtDcuXPVsGFDTZ061XE3lt1ulyRlZmZqwIABqlOnjtq1a6eaNWvqnXfeyd8gAQuxmctPzgMAirR//OMfmjZtmg4ePFjYpQDFgldhFwAAuLp33nlHN998s4KCgrRmzRq98cYbGjhwYGGXBRQbhB0AKOJ27dql1157TSdPnlSVKlU0bNiwHO+kA5AzTmMBAABL4wJlAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaf8P7HAAyQUUKlwAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xu--LnQt--9T"
      },
      "source": [
        "### Question 2: Rating Distribution of movies.\n",
        "\n",
        "Similarly, plot the rating distribution of each movie with respect to (a) the number of ratings per movie and (b) average rating per movie.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00mGFRzM--9T"
      },
      "source": [
        "# Utility to split the data into training and test sets.\n",
        "def split_dataframe(df, holdout_fraction=0.3):\n",
        "    '''Splits a DataFrame into training and test sets.\n",
        "    Args:\n",
        "    df: a dataframe.\n",
        "    holdout_fraction: fraction of dataframe rows to use in the test set.\n",
        "    Returns:\n",
        "    train_df: dataframe for training\n",
        "    test_df: dataframe for testing\n",
        "    '''\n",
        "    eval_df = df.sample(frac=holdout_fraction, replace=False)\n",
        "    \n",
        "    val_df = eval_df.sample(frac=(1/3.0), replace=False)    \n",
        "    test_df = eval_df[~eval_df.index.isin(val_df.index)]\n",
        "    \n",
        "    train_df = df[~df.index.isin(eval_df.index)]\n",
        "    return train_df, val_df, test_df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJL4YAx2--9U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cadad146-d5fd-4c9c-d0c2-c0b907ae244d"
      },
      "source": [
        "print(len(movielens))\n",
        "train, val, test = split_dataframe(movielens)\n",
        "print(len(train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100000\n",
            "70000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMgMpDzV--9U",
        "outputId": "c4084505-7c0a-4fb8-dac9-bbd28496990b",
        "collapsed": true
      },
      "source": [
        "# load train, val, test data for consistency.\n",
        "\n",
        "train = pd.read_csv('ml-100k/train.csv')\n",
        "val = pd.read_csv('ml-100k/val.csv')\n",
        "test = pd.read_csv('ml-100k/test.csv')\n",
        "\n",
        "print(len(train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "70000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpE7gvK4--9U"
      },
      "source": [
        "### Item Neighborhood-based Collaborative Filtering\n",
        "\n",
        "The code described in the next cell provides an initial implementation of neighborhood-based CF using item-based nearest neighbors. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-5Ojmbw--9V"
      },
      "source": [
        "def get_pearson_correlation(item_id, j):\n",
        "\n",
        "    #get pearsom correlation between item_id and j from the set of users who have rated both item_id and j\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #get set of users who have rated both item_id and j\n",
        "    users_rated_both = set(ratings[ratings['movie_id'] == item_id]['user_id']) & set(ratings[ratings['movie_id'] == j]['user_id'])\n",
        "\n",
        "\n",
        "    #for each user belonging to the set, get the rating by the user for item_id and j\n",
        "    #loop through each user and get the rating for item_id and j\n",
        "    ratings_item_id = []\n",
        "    ratings_j = []\n",
        "    total_bias_item_id = []\n",
        "    total_bias_j = []\n",
        "    \n",
        "    numerator = []\n",
        "    denominator = []\n",
        "\n",
        "    mean = ratings['rating'].mean()\n",
        "    \n",
        "    for user in users_rated_both:\n",
        "        curr_rating_item_id = ratings[(ratings['movie_id'] == item_id) & (ratings['user_id'] == user)]['rating'].values[0]\n",
        "        ratings_item_id.append(ratings[(ratings['movie_id'] == item_id) & (ratings['user_id'] == user)]['rating'].values[0])\n",
        "        curr_rating_j = ratings[(ratings['movie_id'] == j) & (ratings['user_id'] == user)]['rating'].values[0]\n",
        "        ratings_j.append(ratings[(ratings['movie_id'] == j) & (ratings['user_id'] == user)]['rating'].values[0])\n",
        "\n",
        "        numerator.append((curr_rating_item_id) * (curr_rating_j))\n",
        "        denominator.append((curr_rating_item_id) ** 2 * (curr_rating_j) ** 2)\n",
        "\n",
        "        #get the bias for each user\n",
        "        #subtract the bias from the rating\n",
        "\n",
        "        # user_bias = users_ratings[users_ratings['user_id'] == user]['rating mean'].values[0]\n",
        "        # item_bias = movies[movies['movie_id'] == item_id]['rating mean'].values[0]\n",
        "        # j_bias = movies[movies['movie_id'] == j]['rating mean'].values[0]\n",
        "\n",
        "        # total_bias_item_id.append(mean + user_bias + item_bias)\n",
        "        # total_bias_j.append(mean + user_bias + j_bias)\n",
        "\n",
        "    #calculate sum of numerator\n",
        "    numerator = np.sum(numerator)\n",
        "    #calculate sum of denominator\n",
        "    denominator = np.sqrt(np.sum(denominator))\n",
        "\n",
        "    #calculate pearson correlation\n",
        "    pearson = numerator / denominator\n",
        "\n",
        "    print(\"pearson by manual calculation: \", pearson)\n",
        "    return pearson\n",
        "    # #calculate pearson correlation between the two items\n",
        "    # pearson = np.corrcoef(ratings_item_id, ratings_j)\n",
        "    # print(\"pearson by numpy: \", pearson)\n",
        "    \n",
        "    # return np.corrcoef(ratings_item_id, ratings_j)[0,1]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADtTEqBa--9V"
      },
      "source": [
        "class NeighborhoodCF():\n",
        "\n",
        "    def __init__(self, train):\n",
        "        self.mu = train['rating'].mean()\n",
        "        self.rating_matrix = sp.csr_matrix((train['rating'], (train['user_id'], train['movie_id']))).toarray()\n",
        "        n_users, n_items = self.rating_matrix.shape[0], self.rating_matrix.shape[1]\n",
        "        self.n_users, self.n_items = n_users, n_items\n",
        "        \n",
        "        # Compute item biases.\n",
        "        self.item_bias, self.user_bias = np.zeros(n_items), np.zeros(n_users)\n",
        "                \n",
        "        item_bias_dict = dict(train.sort_values(['movie_id'],ascending=True).\n",
        "                              groupby(['movie_id'])['rating'].apply(lambda x: sum(x)/len(x) - self.mu))\n",
        "        \n",
        "        for key, val in item_bias_dict.items():\n",
        "            self.item_bias[key] = val\n",
        "\n",
        "        # Compute user biases.\n",
        "        user_bias_dict = train.sort_values(['user_id'],ascending=True).groupby(['user_id']).apply(self.get_user_bias)\n",
        "\n",
        "        for key, val in user_bias_dict.items():\n",
        "            self.user_bias[key] = val\n",
        "        \n",
        "        # Compute a dictionary to store list of items per user (and vice-versa).\n",
        "        self.user_items_dict = defaultdict(lambda: [], dict(train.groupby('user_id')['movie_id'].apply(list)))\n",
        "        self.item_users_dict = defaultdict(lambda : [], dict(train.groupby('movie_id')['user_id'].apply(list)))                \n",
        "        \n",
        "        # Compute movie-movie similarities based on genres.\n",
        "        \n",
        "        movie_genres = train[['movie_id'] + genre_cols].drop_duplicates().sort_values('movie_id')\n",
        "        movie_genres['genre'] = movie_genres[genre_cols].values.tolist()\n",
        "        movie_genres_dict = dict(movie_genres[['movie_id', 'genre']].values)\n",
        "\n",
        "        self.movie_genres_matrix = np.zeros([n_items, len(genre_cols)])\n",
        "\n",
        "        for key, val in movie_genres_dict.items():\n",
        "            self.movie_genres_matrix[key] = val\n",
        "\n",
        "        print(\"moviegenre matrix\", len(self.movie_genres_matrix))   \n",
        "        self.movie_similarity = cosine_similarity(self.movie_genres_matrix)\n",
        "        \n",
        "    def get_user_bias(self, group):    \n",
        "        items = group['movie_id']\n",
        "        ratings = group['rating']\n",
        "        assert len(items) == len(ratings)\n",
        "        result = 0.0\n",
        "\n",
        "        for item, rating in zip(items, ratings):\n",
        "            result += rating - self.item_bias[item] - self.mu\n",
        "\n",
        "        result = result/len(items)\n",
        "        return result\n",
        "    \n",
        "\n",
        "    #This function finds k similar items given the item_id (based on pearson correlation).\n",
        "    def find_nearest_neighbors(self, item_id,  k=5, item_list=None, pearson=False):\n",
        "        if item_list is None:\n",
        "            item_list = list(range(0, self.n_items))\n",
        "        \n",
        "        if pearson:\n",
        "            similarities = np.array([get_pearson_correlation(item_id, j) for j in item_list])\n",
        "        else:\n",
        "            similarities = self.movie_similarity[item_id, item_list]\n",
        "                \n",
        "        similar_items_indices = similarities.argsort()[::-1][:k]\n",
        "        return [item_list[idx] for idx in similar_items_indices]\n",
        "    \n",
        "    def knn_predict(self, user, item, k=5):\n",
        "        numerator, denominator = 0.0, 0.0\n",
        "        neighbor_items = self.user_items_dict[user]\n",
        "        assert k >=0\n",
        "        neighbor_items = self.find_nearest_neighbors(item, k, neighbor_items, pearson=True)\n",
        "        \n",
        "        for j in neighbor_items:\n",
        "            sij = self.movie_similarity[item, j] + 0.000001\n",
        "            denominator += sij         \n",
        "            numerator += sij * (self.rating_matrix[user][j])\n",
        "                \n",
        "        rui = (numerator / denominator)\n",
        "        return rui\n",
        "                \n",
        "\n",
        "\n",
        "    # TODO: complete this function in question 4    \n",
        "    def bias_predict(self, user, item):\n",
        "        pass\n",
        "    \n",
        "    # TODO: complete this function in question 5\n",
        "    def knn_bias_predict(self, user, item, k=5):\n",
        "        pass\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVNwrugL--9a",
        "outputId": "5ef90e6c-8d20-4bc9-b329-388d36aba849",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true
      },
      "source": [
        "model_CF = NeighborhoodCF(train)\n",
        "preds, targets = [], []\n",
        "for idx, row in enumerate(test[['user_id', 'movie_id', 'rating']].values):            \n",
        "    u, i, r = tuple(row)\n",
        "    #pred = model_CF.knn_bias_predict(int(u), int(i), k=50)\n",
        "    pred = model_CF.knn_predict(int(u), int(i), k=15)\n",
        "    #pred = model_CF.bias_predict(int(u), int(i))\n",
        "    \n",
        "    pred = np.clip(pred, 0, 5)\n",
        "    preds.append(pred)\n",
        "    targets.append(r)\n",
        "\n",
        "print (\"MSE on test ratings:\", torch.nn.MSELoss()(torch.tensor(preds), torch.tensor(targets)))\n",
        "print (\"MAE on test ratings:\", torch.nn.L1Loss()(torch.tensor(preds), torch.tensor(targets)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "moviegenre matrix 1682\n",
            "pearson by manual calculation:  1.060430864638069\n",
            "pearson by manual calculation:  1.4984528103154495\n",
            "pearson by manual calculation:  2.108590488016544\n",
            "pearson by manual calculation:  2.1378173259918563\n",
            "pearson by manual calculation:  2.3506656668597548\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0795912380986197\n",
            "pearson by manual calculation:  1.116312611302876\n",
            "pearson by manual calculation:  1.3567477035949578\n",
            "pearson by manual calculation:  1.8306300648455311\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.9639610121239315\n",
            "pearson by manual calculation:  2.18055706720287\n",
            "pearson by manual calculation:  2.2491828581535485\n",
            "pearson by manual calculation:  1.060430864638069\n",
            "pearson by manual calculation:  1.8285851561044473\n",
            "pearson by manual calculation:  1.414213562373095\n",
            "pearson by manual calculation:  1.1671607219845073\n",
            "pearson by manual calculation:  2.146354492351533\n",
            "pearson by manual calculation:  1.1671607219845073\n",
            "pearson by manual calculation:  2.475293958612414\n",
            "pearson by manual calculation:  2.246527642137182\n",
            "pearson by manual calculation:  2.0025559115860245\n",
            "pearson by manual calculation:  1.0486899558217369\n",
            "pearson by manual calculation:  1.414213562373095\n",
            "pearson by manual calculation:  1.934117513513378\n",
            "pearson by manual calculation:  1.1766968108291043\n",
            "pearson by manual calculation:  1.060430864638069\n",
            "pearson by manual calculation:  1.724090128875742\n",
            "pearson by manual calculation:  2.6352183538672302\n",
            "pearson by manual calculation:  1.7972128867239736\n",
            "pearson by manual calculation:  2.0483238479055768\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.6715322113422815\n",
            "pearson by manual calculation:  1.872920173853823\n",
            "pearson by manual calculation:  1.4026687687393442\n",
            "pearson by manual calculation:  1.116312611302876\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.8963992921400699\n",
            "pearson by manual calculation:  1.7143634649587836\n",
            "pearson by manual calculation:  1.8284648156553496\n",
            "pearson by manual calculation:  1.060430864638069\n",
            "pearson by manual calculation:  1.979486637221574\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.116312611302876\n",
            "pearson by manual calculation:  2.268564765070888\n",
            "pearson by manual calculation:  1.270977818604485\n",
            "pearson by manual calculation:  2.331612823705712\n",
            "pearson by manual calculation:  1.1766968108291043\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  2.0984637942690334\n",
            "pearson by manual calculation:  1.0945409092309881\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  2.0743295341071586\n",
            "pearson by manual calculation:  1.060430864638069\n",
            "pearson by manual calculation:  1.116312611302876\n",
            "pearson by manual calculation:  1.1428791884998926\n",
            "pearson by manual calculation:  1.0795912380986197\n",
            "pearson by manual calculation:  1.414213562373095\n",
            "pearson by manual calculation:  1.0795912380986197\n",
            "pearson by manual calculation:  1.6219964498177784\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.991029006045426\n",
            "pearson by manual calculation:  1.4925557853149838\n",
            "pearson by manual calculation:  1.039168997070661\n",
            "pearson by manual calculation:  1.934117513513378\n",
            "pearson by manual calculation:  2.336963919076721\n",
            "pearson by manual calculation:  1.784409012380767\n",
            "pearson by manual calculation:  1.060430864638069\n",
            "pearson by manual calculation:  1.4435074820856104\n",
            "pearson by manual calculation:  1.1428791884998926\n",
            "pearson by manual calculation:  1.8678979297311422\n",
            "pearson by manual calculation:  2.47900273203854\n",
            "pearson by manual calculation:  1.3416407864998738\n",
            "pearson by manual calculation:  1.270977818604485\n",
            "pearson by manual calculation:  2.261597344129335\n",
            "pearson by manual calculation:  1.4814874939752933\n",
            "pearson by manual calculation:  1.0795912380986197\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.116312611302876\n",
            "pearson by manual calculation:  2.19688855094591\n",
            "pearson by manual calculation:  1.8905706613989794\n",
            "pearson by manual calculation:  1.6898159235484365\n",
            "pearson by manual calculation:  1.8650096164806276\n",
            "pearson by manual calculation:  1.3436743470250678\n",
            "pearson by manual calculation:  1.060430864638069\n",
            "pearson by manual calculation:  1.060430864638069\n",
            "pearson by manual calculation:  1.8772610406320833\n",
            "pearson by manual calculation:  1.6858544608470492\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.1852755159795076\n",
            "pearson by manual calculation:  1.0945409092309881\n",
            "pearson by manual calculation:  1.5215349135496974\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  2.558006299135148\n",
            "pearson by manual calculation:  1.4444444444444444\n",
            "pearson by manual calculation:  2.3424290699817982\n",
            "pearson by manual calculation:  1.6678156958735875\n",
            "pearson by manual calculation:  1.7149858514250884\n",
            "pearson by manual calculation:  1.4744195615489712\n",
            "pearson by manual calculation:  1.7464848138535074\n",
            "pearson by manual calculation:  1.0486899558217369\n",
            "pearson by manual calculation:  1.7842102212287423\n",
            "pearson by manual calculation:  2.3610043511828103\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  2.0020857237913203\n",
            "pearson by manual calculation:  2.260837037776963\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  2.293572233077136\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.3100809351859102\n",
            "pearson by manual calculation:  1.150792911137501\n",
            "pearson by manual calculation:  1.4925557853149838\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.6035674514745462\n",
            "pearson by manual calculation:  1.6898159235484365\n",
            "pearson by manual calculation:  2.31893530828676\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.116312611302876\n",
            "pearson by manual calculation:  1.271701568915748\n",
            "pearson by manual calculation:  1.1671607219845073\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.678657610652606\n",
            "pearson by manual calculation:  1.7551598447395271\n",
            "pearson by manual calculation:  1.4268253638383739\n",
            "pearson by manual calculation:  2.4438978734637007\n",
            "pearson by manual calculation:  1.6406939844773856\n",
            "pearson by manual calculation:  1.9098382168101278\n",
            "pearson by manual calculation:  1.7717591356565963\n",
            "pearson by manual calculation:  1.0795912380986197\n",
            "pearson by manual calculation:  1.5179293755116199\n",
            "pearson by manual calculation:  1.212678125181665\n",
            "pearson by manual calculation:  1.9263480415132523\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0795912380986197\n",
            "pearson by manual calculation:  1.212678125181665\n",
            "pearson by manual calculation:  1.7614096918559585\n",
            "pearson by manual calculation:  1.060430864638069\n",
            "pearson by manual calculation:  1.060430864638069\n",
            "pearson by manual calculation:  1.8268933828159366\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.060430864638069\n",
            "pearson by manual calculation:  1.5689290811054724\n",
            "pearson by manual calculation:  2.0035028656007294\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.4122588778696161\n",
            "pearson by manual calculation:  1.414213562373095\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.5328513469458611\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.23942333880154\n",
            "pearson by manual calculation:  1.7440828807877895\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  2.1929216539434218\n",
            "pearson by manual calculation:  1.1206310514564426\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.4135646916977938\n",
            "pearson by manual calculation:  1.4142135623730951\n",
            "pearson by manual calculation:  2.361240363255718\n",
            "pearson by manual calculation:  1.4135646916977938\n",
            "pearson by manual calculation:  1.3416407864998738\n",
            "pearson by manual calculation:  1.0795912380986197\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.712799571891863\n",
            "pearson by manual calculation:  1.4526003741187568\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.4027325024679325\n",
            "pearson by manual calculation:  1.0795912380986197\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.414213562373095\n",
            "pearson by manual calculation:  1.5011106998930268\n",
            "pearson by manual calculation:  1.761542024202177\n",
            "pearson by manual calculation:  1.116312611302876\n",
            "pearson by manual calculation:  1.0795912380986197\n",
            "pearson by manual calculation:  1.5275252316519468\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.4142135623730951\n",
            "pearson by manual calculation:  1.0795912380986197\n",
            "pearson by manual calculation:  1.5015519921378573\n",
            "pearson by manual calculation:  1.6710088364221676\n",
            "pearson by manual calculation:  1.1766968108291043\n",
            "pearson by manual calculation:  1.3448427977044881\n",
            "pearson by manual calculation:  1.414213562373095\n",
            "pearson by manual calculation:  1.3867504905630728\n",
            "pearson by manual calculation:  1.455650685748102\n",
            "pearson by manual calculation:  1.9095718489925029\n",
            "pearson by manual calculation:  2.2842988911415625\n",
            "pearson by manual calculation:  1.116312611302876\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  2.0501475036069783\n",
            "pearson by manual calculation:  1.1852755159795076\n",
            "pearson by manual calculation:  1.212678125181665\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.212678125181665\n",
            "pearson by manual calculation:  1.3867504905630728\n",
            "pearson by manual calculation:  1.8014079000979237\n",
            "pearson by manual calculation:  1.3416407864998738\n",
            "pearson by manual calculation:  1.4694160994998617\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.2649110640673518\n",
            "pearson by manual calculation:  1.0795912380986197\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.060430864638069\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.060430864638069\n",
            "pearson by manual calculation:  1.150792911137501\n",
            "pearson by manual calculation:  1.2649110640673518\n",
            "pearson by manual calculation:  1.1877113736973437\n",
            "pearson by manual calculation:  1.23942333880154\n",
            "pearson by manual calculation:  1.1760704751213287\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.414213562373095\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.7461361214025837\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.5689290811054724\n",
            "pearson by manual calculation:  1.5773568421598623\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.4985372985307104\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.5198827810467064\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.1877113736973437\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.386750490563073\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.3242443839434612\n",
            "pearson by manual calculation:  1.6254851075486312\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0643041683803829\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0795912380986197\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.060430864638069\n",
            "pearson by manual calculation:  1.176696810829104\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.4055638569974547\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.212678125181665\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.116312611302876\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.060430864638069\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0795912380986197\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.150792911137501\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  1.0\n",
            "pearson by manual calculation:  3.8056900097764066\n",
            "pearson by manual calculation:  6.5321221772498195\n",
            "pearson by manual calculation:  7.305382355182974\n",
            "pearson by manual calculation:  5.448492379575548\n",
            "pearson by manual calculation:  7.726559844107065\n",
            "pearson by manual calculation:  4.138415939279966\n",
            "pearson by manual calculation:  7.970426780678975\n",
            "pearson by manual calculation:  8.121329854211648\n",
            "pearson by manual calculation:  7.463070232344618\n",
            "pearson by manual calculation:  3.1064942859220355\n",
            "pearson by manual calculation:  8.41784844715404\n",
            "pearson by manual calculation:  6.702075888741303\n",
            "pearson by manual calculation:  2.294373758435235\n",
            "pearson by manual calculation:  5.361429905320889\n",
            "pearson by manual calculation:  6.794146354612996\n",
            "pearson by manual calculation:  8.201126753949698\n",
            "pearson by manual calculation:  8.12063861507706\n",
            "pearson by manual calculation:  6.25\n",
            "pearson by manual calculation:  9.015192814456235\n",
            "pearson by manual calculation:  8.00445490060731\n",
            "pearson by manual calculation:  8.063041747692468\n",
            "pearson by manual calculation:  6.283351016774409\n",
            "pearson by manual calculation:  5.620831409375595\n",
            "pearson by manual calculation:  7.9190158913922035\n",
            "pearson by manual calculation:  5.150063697586062\n",
            "pearson by manual calculation:  8.496295755492048\n",
            "pearson by manual calculation:  6.753166288970943\n",
            "pearson by manual calculation:  6.741935483870968\n",
            "pearson by manual calculation:  2.8311496464321815\n",
            "pearson by manual calculation:  4.928571428571429\n",
            "pearson by manual calculation:  6.86545613339759\n",
            "pearson by manual calculation:  6.422529508361343\n",
            "pearson by manual calculation:  7.22592526554246\n",
            "pearson by manual calculation:  9.154565614511384\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-90e3014f0c94>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#pred = model_CF.knn_bias_predict(int(u), int(i), k=50)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_CF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mknn_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m#pred = model_CF.bias_predict(int(u), int(i))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-8280e507fa82>\u001b[0m in \u001b[0;36mknn_predict\u001b[0;34m(self, user, item, k)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mneighbor_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_items_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m>=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mneighbor_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_nearest_neighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneighbor_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpearson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mneighbor_items\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-8280e507fa82>\u001b[0m in \u001b[0;36mfind_nearest_neighbors\u001b[0;34m(self, item_id, k, item_list, pearson)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpearson\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0msimilarities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mget_pearson_correlation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitem_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0msimilarities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmovie_similarity\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-8280e507fa82>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpearson\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0msimilarities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mget_pearson_correlation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitem_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0msimilarities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmovie_similarity\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-1e47e241cffb>\u001b[0m in \u001b[0;36mget_pearson_correlation\u001b[0;34m(item_id, j)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mratings_item_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'movie_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mitem_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rating'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mcurr_rating_j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'movie_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rating'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mratings_j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'movie_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rating'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mnumerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_rating_item_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcurr_rating_j\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3494\u001b[0m         \u001b[0;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3495\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3496\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3498\u001b[0m         \u001b[0;31m# We are left with two options: a single key, and a collection of keys,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_bool_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3548\u001b[0m         \u001b[0;31m# be reindexed to match DataFrame rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3549\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3550\u001b[0;31m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3551\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-P2pbxPE--9d"
      },
      "source": [
        "### Question 3: Neighborhood-based CF (impact of neighborhood size)\n",
        "\n",
        "Run the above neighborhood-based recommender `knn_predict` for different neighborhood sizes $K = \\{1, 5, 10, 50, 100\\}$ and plot the variation in test MSE error with respect to $K$. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rna-tYVO--9d"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUZSSBWI--9e"
      },
      "source": [
        "### Question 4: Bias recommender baseline. \n",
        "\n",
        "Complete the `bias_predict` function within the `NeighborhoodCF` class to implement the baseline recommender using user-specific, item-specific and global bias factors. $ r_{ui} = b_u + b_i + \\mu $.\n",
        "\n",
        "How does the performance of bias prediction baseline compare with the nearest neighbor recommender in `knn_predict` ? Explain.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtBsEMIJ--9e"
      },
      "source": [
        "### Question 5: Neighborhood-based CF with bias\n",
        "\n",
        "\n",
        "Complete the `knn_bias_predict` function within the `NeighborhoodCF` class to implement the nearest neighborhood  recommender using user-specific, item-specific and global bias factors. (Extend `knn_predict` with biases)\n",
        "\n",
        "$$\\hat{r}_{u,i} = b_{u,i}+ \\frac{\\sum_{j \\in S^k(i;u)} s_{i,j} \\times (r_{u,j} - b_{u,j}) }{\\sum_{j \\in S^k(i;u)} s_{i,j}} $$\n",
        "\n",
        "\n",
        "$$ b_{u,i} =  \\mu + b_u + b_i$$\n",
        "\n",
        "\n",
        "How does the performance of `knn_bias_predict` compare with `knn_predict` and `bias_predict` ? Explain."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4gLFY33--9e"
      },
      "source": [
        "### Matrix Factorization based Collaborative Filtering\n",
        "\n",
        "This is an implementation of Matrix Factorization using a machine learning framework PyTorch - https://pytorch.org/ with automatic gradient computation.\n",
        "\n",
        "Instead of SGD, we use PyTorch due to better optimizers and batch-wise efficient computations.  \n",
        "\n",
        "Unlike the neighborhood-based CF model which is non-parametric, the MF model has multiple learnable parameters (latent factors) and hyper-parameters (learning rate, number of latent factors, batch size, etc.). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsYWoHSF--9e"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MatrixFactorization(torch.nn.Module):\n",
        "    def __init__(self, n_users, n_items, n_factors=20, bias=False):\n",
        "        super().__init__()\n",
        "        # create user embeddings\n",
        "        self.user_factors = torch.nn.Embedding(n_users, n_factors)\n",
        "        self.bias = bias\n",
        "        \n",
        "        # create item embeddings\n",
        "        self.item_factors = torch.nn.Embedding(n_items, n_factors)\n",
        "        if self.bias:\n",
        "            self.user_bias = torch.nn.Embedding(n_users, 1)\n",
        "            self.item_bias = torch.nn.Embedding(n_items, 1)\n",
        "            \n",
        "            self.user_bias.weight.data.fill_(0.)\n",
        "            self.user_bias.weight.data.fill_(0.)\n",
        "        \n",
        "        torch.nn.init.xavier_uniform_(self.user_factors.weight)\n",
        "        torch.nn.init.xavier_uniform_(self.item_factors.weight)\n",
        "        \n",
        "    def forward(self, user, item):\n",
        "        # matrix multiplication\n",
        "        if self.bias:\n",
        "            return self.user_bias(user).squeeze(-1) + self.item_bias(item).squeeze(-1) + \\\n",
        "                (self.user_factors(user)*self.item_factors(item)).sum(-1)\n",
        "        else:\n",
        "            return (self.user_factors(user)*self.item_factors(item)).sum(-1)\n",
        "\n",
        "    def predict(self, user, item):\n",
        "        return self.forward(user, item)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7I9pzZF--9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "236cd46a-11bd-4c9e-8254-b246d6032512",
        "collapsed": true
      },
      "source": [
        "# hyper-parameters.\n",
        "\n",
        "lr = 1e-3\n",
        "batch_size = 1024\n",
        "n_factors = 128\n",
        "\n",
        "model_MF = MatrixFactorization(model_CF.n_users, model_CF.n_items, n_factors=n_factors, bias=False)\n",
        "\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model_MF.parameters(), lr=lr, weight_decay=1e-4)\n",
        "\n",
        "train_ratings = train[['user_id', 'movie_id', 'rating']].values\n",
        "test_ratings = test[['user_id', 'movie_id', 'rating']].values\n",
        "val_ratings = val[['user_id', 'movie_id', 'rating']].values\n",
        "\n",
        "def test_model(model_MF, test_ratings):\n",
        "    n_batches = len(test_ratings) // batch_size\n",
        "    preds, targets = [], []\n",
        "    for b in range(n_batches):\n",
        "        batch_data = test_ratings[(b* batch_size) : (b+1)* batch_size]        \n",
        "        batch_users, batch_items, batch_ratings = batch_data[:, 0], batch_data[:, 1], batch_data[:, 2]\n",
        "        user, item = torch.LongTensor(batch_users), torch.LongTensor(batch_items)\n",
        "        pred = model_MF.predict(user, item).detach()\n",
        "        pred = np.clip(pred, 0, 5)\n",
        "        preds.append(pred)\n",
        "        targets.append(batch_ratings)\n",
        "    preds, targets = np.concatenate(preds), np.concatenate(targets)\n",
        "    test_loss = loss_fn(torch.tensor(preds), torch.tensor(targets)).item()\n",
        "    print (\"test loss: \", test_loss)\n",
        "    return test_loss\n",
        "\n",
        "def validate_model(model_MF, val_ratings):\n",
        "    n_batches = len(val_ratings) // batch_size\n",
        "    preds, targets = [], []\n",
        "    for b in range(n_batches):\n",
        "        batch_data = val_ratings[(b* batch_size) : (b+1)* batch_size]        \n",
        "        batch_users, batch_items, batch_ratings = batch_data[:, 0], batch_data[:, 1], batch_data[:, 2]\n",
        "        user, item = torch.LongTensor(batch_users), torch.LongTensor(batch_items)\n",
        "        pred = model_MF.predict(user, item).detach()\n",
        "        pred = np.clip(pred, 0, 5)\n",
        "        preds.append(pred)\n",
        "        targets.append(batch_ratings)\n",
        "    preds, targets = np.concatenate(preds), np.concatenate(targets)\n",
        "    val_loss = loss_fn(torch.tensor(preds), torch.tensor(targets)).item()\n",
        "    print (\"validation loss: \", val_loss)\n",
        "    return val_loss\n",
        "\n",
        "train_loss_master = []\n",
        "test_loss_master = [] \n",
        "val_loss_master = [] \n",
        "\n",
        "for epoch in range(0, 150):\n",
        "    train_loss = 0.0\n",
        "    n_batches = len(train_ratings) // batch_size\n",
        "    if train_ratings % batch_size is not 0:\n",
        "        n_batches += 1\n",
        "    np.random.shuffle(train_ratings)\n",
        "    for b in range(n_batches):\n",
        "        batch_data = train_ratings[(b* batch_size) : (b+1)* batch_size]\n",
        "        # get user, item and rating data\n",
        "        batch_users, batch_items, batch_ratings = batch_data[:, 0], batch_data[:, 1], batch_data[:, 2]\n",
        "        user, item = torch.LongTensor(batch_users), torch.LongTensor(batch_items)\n",
        "        rating = torch.FloatTensor(batch_ratings)\n",
        "        optimizer.zero_grad()\n",
        "        model_MF.zero_grad()\n",
        "        \n",
        "        # predict\n",
        "        prediction = model_MF(user, item)\n",
        "        loss = loss_fn(prediction, rating)\n",
        "\n",
        "        # backpropagate\n",
        "        loss.backward()\n",
        "\n",
        "        # update weights\n",
        "        optimizer.step()\n",
        "        \n",
        "        train_loss += loss.item()\n",
        "        \n",
        "    print (\"epoch {}: train loss {}\".format(epoch, train_loss/n_batches))\n",
        "    train_loss_master.append(train_loss/n_batches)\n",
        "    test_loss_master.append(test_model(model_MF, test_ratings))   \n",
        "    val_loss_master.append(validate_model(model_MF, val_ratings))    \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:55: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "<>:55: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "<ipython-input-20-a3027cee8d57>:55: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "  if train_ratings % batch_size is not 0:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0: train loss 13.744627137115037\n",
            "test loss:  13.56635462625385\n",
            "validation loss:  13.663381223434868\n",
            "epoch 1: train loss 13.324600731117139\n",
            "test loss:  12.52340292777245\n",
            "validation loss:  12.625164289798237\n",
            "epoch 2: train loss 10.101875256800998\n",
            "test loss:  6.832573374518835\n",
            "validation loss:  6.9538024079616525\n",
            "epoch 3: train loss 3.955044400864753\n",
            "test loss:  2.178681100280908\n",
            "validation loss:  2.2636133207700895\n",
            "epoch 4: train loss 1.5801796723103179\n",
            "test loss:  1.3427758689094298\n",
            "validation loss:  1.3790652844779616\n",
            "epoch 5: train loss 1.133324448613153\n",
            "test loss:  1.120980133962656\n",
            "validation loss:  1.1406042984946343\n",
            "epoch 6: train loss 0.9850134901378466\n",
            "test loss:  1.0304020056069518\n",
            "validation loss:  1.0451967830846784\n",
            "epoch 7: train loss 0.9159693536551102\n",
            "test loss:  0.9874738707776823\n",
            "validation loss:  0.9998790235209134\n",
            "epoch 8: train loss 0.8769109655117643\n",
            "test loss:  0.9644246562987399\n",
            "validation loss:  0.9734198752736387\n",
            "epoch 9: train loss 0.8513010386107625\n",
            "test loss:  0.9481649907242958\n",
            "validation loss:  0.957149696902114\n",
            "epoch 10: train loss 0.8303752446520156\n",
            "test loss:  0.9359715168790818\n",
            "validation loss:  0.9451393550491104\n",
            "epoch 11: train loss 0.8124932163003562\n",
            "test loss:  0.9274623836242802\n",
            "validation loss:  0.9372130920166349\n",
            "epoch 12: train loss 0.7941374329553135\n",
            "test loss:  0.9201087898075573\n",
            "validation loss:  0.9294959786504003\n",
            "epoch 13: train loss 0.7791832132615905\n",
            "test loss:  0.9110622833756625\n",
            "validation loss:  0.9206902646556929\n",
            "epoch 14: train loss 0.7601577985113945\n",
            "test loss:  0.9044577393275004\n",
            "validation loss:  0.9158245055628242\n",
            "epoch 15: train loss 0.7427564608877983\n",
            "test loss:  0.8985313388707211\n",
            "validation loss:  0.9101799920353785\n",
            "epoch 16: train loss 0.7247742569964865\n",
            "test loss:  0.8948494311449797\n",
            "validation loss:  0.9064521080522492\n",
            "epoch 17: train loss 0.7069263190462969\n",
            "test loss:  0.8905404063425129\n",
            "validation loss:  0.9030664291034043\n",
            "epoch 18: train loss 0.6882560218589894\n",
            "test loss:  0.885970873979306\n",
            "validation loss:  0.9002911349602157\n",
            "epoch 19: train loss 0.670861562093099\n",
            "test loss:  0.8829723784531555\n",
            "validation loss:  0.8964944926164632\n",
            "epoch 20: train loss 0.6526068068932795\n",
            "test loss:  0.879674117528622\n",
            "validation loss:  0.8950826892251654\n",
            "epoch 21: train loss 0.6352188241654548\n",
            "test loss:  0.8779958294190777\n",
            "validation loss:  0.8947974953835032\n",
            "epoch 22: train loss 0.6162421098653821\n",
            "test loss:  0.8766052295239934\n",
            "validation loss:  0.8932785657565658\n",
            "epoch 23: train loss 0.5980480391046276\n",
            "test loss:  0.8756527212017924\n",
            "validation loss:  0.8919813721213478\n",
            "epoch 24: train loss 0.5797314497007839\n",
            "test loss:  0.8755219155650134\n",
            "validation loss:  0.8913329512992464\n",
            "epoch 25: train loss 0.5627487107463505\n",
            "test loss:  0.874822319581039\n",
            "validation loss:  0.8906136768603393\n",
            "epoch 26: train loss 0.5451177103795867\n",
            "test loss:  0.8746652573141747\n",
            "validation loss:  0.8895057449023782\n",
            "epoch 27: train loss 0.5269003488879273\n",
            "test loss:  0.8760405047983015\n",
            "validation loss:  0.891341505310311\n",
            "epoch 28: train loss 0.508870882400568\n",
            "test loss:  0.8757513648552543\n",
            "validation loss:  0.8910504878763601\n",
            "epoch 29: train loss 0.49221426507701044\n",
            "test loss:  0.8774478025421611\n",
            "validation loss:  0.8928602756868403\n",
            "epoch 30: train loss 0.47578242680300836\n",
            "test loss:  0.8784882159796786\n",
            "validation loss:  0.89356572980021\n",
            "epoch 31: train loss 0.4590431797331658\n",
            "test loss:  0.880143982766954\n",
            "validation loss:  0.8940184258059891\n",
            "epoch 32: train loss 0.4425855849100196\n",
            "test loss:  0.8818290790475075\n",
            "validation loss:  0.8961678276566258\n",
            "epoch 33: train loss 0.4268481023069741\n",
            "test loss:  0.8828338128520532\n",
            "validation loss:  0.8968013753230785\n",
            "epoch 34: train loss 0.4113941296287205\n",
            "test loss:  0.8861720887901507\n",
            "validation loss:  0.90015120815124\n",
            "epoch 35: train loss 0.39740950430648914\n",
            "test loss:  0.8883204671320093\n",
            "validation loss:  0.9018577798944428\n",
            "epoch 36: train loss 0.38176620092944824\n",
            "test loss:  0.8906010716236951\n",
            "validation loss:  0.9042161107046758\n",
            "epoch 37: train loss 0.36839784271475196\n",
            "test loss:  0.8928215479129192\n",
            "validation loss:  0.9065736552086948\n",
            "epoch 38: train loss 0.3555195469787155\n",
            "test loss:  0.8955938486127643\n",
            "validation loss:  0.9086734359186232\n",
            "epoch 39: train loss 0.3421845176945562\n",
            "test loss:  0.8987476596521651\n",
            "validation loss:  0.9121937967433903\n",
            "epoch 40: train loss 0.328960082669189\n",
            "test loss:  0.9015183994407495\n",
            "validation loss:  0.9146974377735838\n",
            "epoch 41: train loss 0.31701441951419995\n",
            "test loss:  0.9055276673251078\n",
            "validation loss:  0.916885701170625\n",
            "epoch 42: train loss 0.3052569701187853\n",
            "test loss:  0.9080303396589546\n",
            "validation loss:  0.9210790012141992\n",
            "epoch 43: train loss 0.2941614510356516\n",
            "test loss:  0.9100887967518495\n",
            "validation loss:  0.9243550295249897\n",
            "epoch 44: train loss 0.2842234666796698\n",
            "test loss:  0.9128057889037741\n",
            "validation loss:  0.9251928493700494\n",
            "epoch 45: train loss 0.27324685691923334\n",
            "test loss:  0.9161434884666484\n",
            "validation loss:  0.9298045119410333\n",
            "epoch 46: train loss 0.26381267974342126\n",
            "test loss:  0.918806697490257\n",
            "validation loss:  0.9332112543835377\n",
            "epoch 47: train loss 0.25373239836831024\n",
            "test loss:  0.9217864152894745\n",
            "validation loss:  0.935100376584217\n",
            "epoch 48: train loss 0.2449333440998326\n",
            "test loss:  0.9249967355675002\n",
            "validation loss:  0.9380690878175523\n",
            "epoch 49: train loss 0.2367272510908652\n",
            "test loss:  0.9269678370064418\n",
            "validation loss:  0.9405683711548729\n",
            "epoch 50: train loss 0.22864385575487994\n",
            "test loss:  0.9291270165233755\n",
            "validation loss:  0.9435069166422251\n",
            "epoch 51: train loss 0.22023694541143335\n",
            "test loss:  0.93430457356708\n",
            "validation loss:  0.9465984693237688\n",
            "epoch 52: train loss 0.21331655158512836\n",
            "test loss:  0.9355953499085485\n",
            "validation loss:  0.9476742702419657\n",
            "epoch 53: train loss 0.20595374336277228\n",
            "test loss:  0.9387618529596665\n",
            "validation loss:  0.9518973903373852\n",
            "epoch 54: train loss 0.1994185048168984\n",
            "test loss:  0.940039471287886\n",
            "validation loss:  0.9551653276363682\n",
            "epoch 55: train loss 0.1930665810039078\n",
            "test loss:  0.942953402020445\n",
            "validation loss:  0.9572699619157596\n",
            "epoch 56: train loss 0.18766183006590692\n",
            "test loss:  0.9443218049270218\n",
            "validation loss:  0.9594035062874925\n",
            "epoch 57: train loss 0.18124835560287256\n",
            "test loss:  0.9463357232254843\n",
            "validation loss:  0.9619146042858758\n",
            "epoch 58: train loss 0.17623413429744\n",
            "test loss:  0.9495825701887469\n",
            "validation loss:  0.9636950976235276\n",
            "epoch 59: train loss 0.17102363640847412\n",
            "test loss:  0.9512895011561427\n",
            "validation loss:  0.9673684470675465\n",
            "epoch 60: train loss 0.1657450717428456\n",
            "test loss:  0.9536546867020508\n",
            "validation loss:  0.9699712126509108\n",
            "epoch 61: train loss 0.16141528539035632\n",
            "test loss:  0.9549780705423838\n",
            "validation loss:  0.9701653744899001\n",
            "epoch 62: train loss 0.1572692003371059\n",
            "test loss:  0.9555252103495108\n",
            "validation loss:  0.9728444554392538\n",
            "epoch 63: train loss 0.15341919228650522\n",
            "test loss:  0.9586586671974073\n",
            "validation loss:  0.9743116978912865\n",
            "epoch 64: train loss 0.14925815748131793\n",
            "test loss:  0.9608919224953346\n",
            "validation loss:  0.9776831157154058\n",
            "epoch 65: train loss 0.1451196642457575\n",
            "test loss:  0.9625515955106528\n",
            "validation loss:  0.9792534808229101\n",
            "epoch 66: train loss 0.14209001522133316\n",
            "test loss:  0.9629473782231716\n",
            "validation loss:  0.9781434184497838\n",
            "epoch 67: train loss 0.13880072577276092\n",
            "test loss:  0.9652519550243057\n",
            "validation loss:  0.9817140571832623\n",
            "epoch 68: train loss 0.13554761677548505\n",
            "test loss:  0.9663275366063097\n",
            "validation loss:  0.9819451513450053\n",
            "epoch 69: train loss 0.13255218481240066\n",
            "test loss:  0.9679411548535689\n",
            "validation loss:  0.9839102708450866\n",
            "epoch 70: train loss 0.12968593555084174\n",
            "test loss:  0.969187948271128\n",
            "validation loss:  0.9858967765373028\n",
            "epoch 71: train loss 0.1275221318870351\n",
            "test loss:  0.9702273047212079\n",
            "validation loss:  0.9856375709100335\n",
            "epoch 72: train loss 0.12445578378611717\n",
            "test loss:  0.970459136233341\n",
            "validation loss:  0.9879790408876217\n",
            "epoch 73: train loss 0.12193582466115123\n",
            "test loss:  0.972109202082674\n",
            "validation loss:  0.9902112005380851\n",
            "epoch 74: train loss 0.11982729415530743\n",
            "test loss:  0.9736524872243235\n",
            "validation loss:  0.9919558342780248\n",
            "epoch 75: train loss 0.11785307958506155\n",
            "test loss:  0.9746453369600763\n",
            "validation loss:  0.9916432792176129\n",
            "epoch 76: train loss 0.1157938043276469\n",
            "test loss:  0.9737826716255995\n",
            "validation loss:  0.9920284125623736\n",
            "epoch 77: train loss 0.11386028266903284\n",
            "test loss:  0.9765000182035992\n",
            "validation loss:  0.9941962704927438\n",
            "epoch 78: train loss 0.11202369036449902\n",
            "test loss:  0.9770373379365496\n",
            "validation loss:  0.9942560338973983\n",
            "epoch 79: train loss 0.11055869576723679\n",
            "test loss:  0.9780499372034742\n",
            "validation loss:  0.9963765303787915\n",
            "epoch 80: train loss 0.10869037392346756\n",
            "test loss:  0.9790219328219019\n",
            "validation loss:  0.99618651169404\n",
            "epoch 81: train loss 0.10760432481765747\n",
            "test loss:  0.9804354021276295\n",
            "validation loss:  0.9984085610555972\n",
            "epoch 82: train loss 0.10582912680895432\n",
            "test loss:  0.9799854691973402\n",
            "validation loss:  0.9985695307579395\n",
            "epoch 83: train loss 0.10392235370649808\n",
            "test loss:  0.9801152419093881\n",
            "validation loss:  0.9986307211032744\n",
            "epoch 84: train loss 0.10308538971171863\n",
            "test loss:  0.9799877227998156\n",
            "validation loss:  0.9991475703577832\n",
            "epoch 85: train loss 0.1015282226861387\n",
            "test loss:  0.9806186366640557\n",
            "validation loss:  0.9997017781522027\n",
            "epoch 86: train loss 0.10067559746296509\n",
            "test loss:  0.9823178331260102\n",
            "validation loss:  1.001714066744842\n",
            "epoch 87: train loss 0.09944853467353876\n",
            "test loss:  0.9834340499337484\n",
            "validation loss:  1.0024436819575033\n",
            "epoch 88: train loss 0.0983728459779767\n",
            "test loss:  0.9828952960904328\n",
            "validation loss:  1.003601994420333\n",
            "epoch 89: train loss 0.09723153116478436\n",
            "test loss:  0.983176279379849\n",
            "validation loss:  1.0044661749703476\n",
            "epoch 90: train loss 0.09626080138959746\n",
            "test loss:  0.984139778295801\n",
            "validation loss:  1.0037756057411136\n",
            "epoch 91: train loss 0.095780775922796\n",
            "test loss:  0.9838967851877127\n",
            "validation loss:  1.0037632878534193\n",
            "epoch 92: train loss 0.09479963120774947\n",
            "test loss:  0.9853715264661019\n",
            "validation loss:  1.0046562133972357\n",
            "epoch 93: train loss 0.09380312901044237\n",
            "test loss:  0.983558870926166\n",
            "validation loss:  1.0037747419994296\n",
            "epoch 94: train loss 0.09315820265075435\n",
            "test loss:  0.9849287815367906\n",
            "validation loss:  1.0060621532458154\n",
            "epoch 95: train loss 0.0922348664506622\n",
            "test loss:  0.9852996624036576\n",
            "validation loss:  1.0061246789283986\n",
            "epoch 96: train loss 0.09164912696333899\n",
            "test loss:  0.9850709870281249\n",
            "validation loss:  1.0068845817491423\n",
            "epoch 97: train loss 0.09107174681148668\n",
            "test loss:  0.9860018634651433\n",
            "validation loss:  1.0062653930615044\n",
            "epoch 98: train loss 0.09048256213250368\n",
            "test loss:  0.9854266213371654\n",
            "validation loss:  1.0079409818028433\n",
            "epoch 99: train loss 0.08979592623486035\n",
            "test loss:  0.9864890967082804\n",
            "validation loss:  1.0079149743663267\n",
            "epoch 100: train loss 0.08893742790256721\n",
            "test loss:  0.9862564430692573\n",
            "validation loss:  1.0076810896969262\n",
            "epoch 101: train loss 0.08851436180049095\n",
            "test loss:  0.9868772384202749\n",
            "validation loss:  1.010679435017347\n",
            "epoch 102: train loss 0.08813640216122502\n",
            "test loss:  0.9860486780671662\n",
            "validation loss:  1.0090387009368218\n",
            "epoch 103: train loss 0.08735425219587657\n",
            "test loss:  0.9863335217017636\n",
            "validation loss:  1.00931990929246\n",
            "epoch 104: train loss 0.08749820799499318\n",
            "test loss:  0.9859250263905854\n",
            "validation loss:  1.0082820624809015\n",
            "epoch 105: train loss 0.08645516407230626\n",
            "test loss:  0.9877986766940229\n",
            "validation loss:  1.0115944993923982\n",
            "epoch 106: train loss 0.08625488253175348\n",
            "test loss:  0.9868052738741274\n",
            "validation loss:  1.0089253140369494\n",
            "epoch 107: train loss 0.0858583410364994\n",
            "test loss:  0.9862029833782576\n",
            "validation loss:  1.009301183711628\n",
            "epoch 108: train loss 0.08550239829481512\n",
            "test loss:  0.9860210585230548\n",
            "validation loss:  1.0097792504899274\n",
            "epoch 109: train loss 0.08502484750056612\n",
            "test loss:  0.987120673680301\n",
            "validation loss:  1.0116159187101887\n",
            "epoch 110: train loss 0.08513652025789455\n",
            "test loss:  0.9877085219931692\n",
            "validation loss:  1.009544846680826\n",
            "epoch 111: train loss 0.0841833906977073\n",
            "test loss:  0.9875882555282448\n",
            "validation loss:  1.0088250853999543\n",
            "epoch 112: train loss 0.08405512916869011\n",
            "test loss:  0.9884504870246029\n",
            "validation loss:  1.0084404899680384\n",
            "epoch 113: train loss 0.08378481713757999\n",
            "test loss:  0.9888091530950517\n",
            "validation loss:  1.010531753545589\n",
            "epoch 114: train loss 0.08324121824209241\n",
            "test loss:  0.9863097644530029\n",
            "validation loss:  1.0093220778525867\n",
            "epoch 115: train loss 0.0831020422603773\n",
            "test loss:  0.9880907096104963\n",
            "validation loss:  1.0121386265623353\n",
            "epoch 116: train loss 0.08288310295429782\n",
            "test loss:  0.9872256249460825\n",
            "validation loss:  1.0099965565048996\n",
            "epoch 117: train loss 0.08274064277825148\n",
            "test loss:  0.9884155261921285\n",
            "validation loss:  1.011060424884191\n",
            "epoch 118: train loss 0.08259634252475656\n",
            "test loss:  0.9877360131782813\n",
            "validation loss:  1.0108262830606354\n",
            "epoch 119: train loss 0.08203299375979797\n",
            "test loss:  0.9870980048570263\n",
            "validation loss:  1.0110579654839795\n",
            "epoch 120: train loss 0.08177530754735504\n",
            "test loss:  0.987362590127281\n",
            "validation loss:  1.0099212644584066\n",
            "epoch 121: train loss 0.0811518950090892\n",
            "test loss:  0.9870695912146116\n",
            "validation loss:  1.0108278940611872\n",
            "epoch 122: train loss 0.08124277459970419\n",
            "test loss:  0.9882528881200926\n",
            "validation loss:  1.0101238874276517\n",
            "epoch 123: train loss 0.08104481321314107\n",
            "test loss:  0.9878005551742473\n",
            "validation loss:  1.0101993775481382\n",
            "epoch 124: train loss 0.08092785982981972\n",
            "test loss:  0.9872673507382391\n",
            "validation loss:  1.0114897570328458\n",
            "epoch 125: train loss 0.08087902591712233\n",
            "test loss:  0.9868329198558226\n",
            "validation loss:  1.0095827253053093\n",
            "epoch 126: train loss 0.08044078973108444\n",
            "test loss:  0.9858480521579103\n",
            "validation loss:  1.0104471819760952\n",
            "epoch 127: train loss 0.08014162057551785\n",
            "test loss:  0.9874090129203379\n",
            "validation loss:  1.0106331415522374\n",
            "epoch 128: train loss 0.08034934330245723\n",
            "test loss:  0.9869282883306925\n",
            "validation loss:  1.0100098093456635\n",
            "epoch 129: train loss 0.08017927548591641\n",
            "test loss:  0.9871084402119299\n",
            "validation loss:  1.0109376824955882\n",
            "epoch 130: train loss 0.0797496224227159\n",
            "test loss:  0.9873957290338637\n",
            "validation loss:  1.0106710050983867\n",
            "epoch 131: train loss 0.07956623134837634\n",
            "test loss:  0.987423793550397\n",
            "validation loss:  1.0115442856819041\n",
            "epoch 132: train loss 0.07966528854508331\n",
            "test loss:  0.9868473012089714\n",
            "validation loss:  1.0119802753322231\n",
            "epoch 133: train loss 0.07924408195675284\n",
            "test loss:  0.987120143538165\n",
            "validation loss:  1.0114366901853653\n",
            "epoch 134: train loss 0.07924696749103242\n",
            "test loss:  0.986242904045617\n",
            "validation loss:  1.0107667402039366\n",
            "epoch 135: train loss 0.07892401170903358\n",
            "test loss:  0.9871225638829508\n",
            "validation loss:  1.0118053659006343\n",
            "epoch 136: train loss 0.0790998573968376\n",
            "test loss:  0.9867909492413999\n",
            "validation loss:  1.0098540419287676\n",
            "epoch 137: train loss 0.07900380672536035\n",
            "test loss:  0.9866142591133823\n",
            "validation loss:  1.0103135475665974\n",
            "epoch 138: train loss 0.07832459830071616\n",
            "test loss:  0.9871785218684426\n",
            "validation loss:  1.011128085881508\n",
            "epoch 139: train loss 0.07837755465205165\n",
            "test loss:  0.98751624497098\n",
            "validation loss:  1.0123302938126906\n",
            "epoch 140: train loss 0.07860264138898988\n",
            "test loss:  0.9872454569617889\n",
            "validation loss:  1.0112888729282519\n",
            "epoch 141: train loss 0.07865955810184064\n",
            "test loss:  0.9857724671075905\n",
            "validation loss:  1.0105619253959925\n",
            "epoch 142: train loss 0.0781626490795094\n",
            "test loss:  0.9864925402970395\n",
            "validation loss:  1.0111662056860122\n",
            "epoch 143: train loss 0.07806673980709436\n",
            "test loss:  0.9872246097030394\n",
            "validation loss:  1.0109732929938322\n",
            "epoch 144: train loss 0.07805452700974284\n",
            "test loss:  0.9851202606825895\n",
            "validation loss:  1.0100406379319185\n",
            "epoch 145: train loss 0.07761302250234978\n",
            "test loss:  0.9858666537866156\n",
            "validation loss:  1.0088458214069942\n",
            "epoch 146: train loss 0.0776669393307057\n",
            "test loss:  0.9852851835839825\n",
            "validation loss:  1.0103231511422142\n",
            "epoch 147: train loss 0.07724853200109108\n",
            "test loss:  0.9855012636339673\n",
            "validation loss:  1.0125015997447169\n",
            "epoch 148: train loss 0.07738798435615457\n",
            "test loss:  0.9860378866167429\n",
            "validation loss:  1.0115657157674376\n",
            "epoch 149: train loss 0.07723914162404295\n",
            "test loss:  0.9863255656088881\n",
            "validation loss:  1.0128793692996372\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sor1H94v--9f"
      },
      "source": [
        "### Question 6: Matrix Factorization (MF) based CF (loss curves)\n",
        "\n",
        "Run the MF model for 150 epochs (or until convergence) and plot the variation in train and test errors (MSE). What do you observe? At which epoch should we choose the best model? \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPp_BTk4--9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "8952b2c6-d5ef-47a2-d85c-50653267e1e5"
      },
      "source": [
        "#plot the variation in train and test errors (MSE) from train_loss_master and test_loss_master\n",
        "plt.plot(train_loss_master[0:20], label='train')\n",
        "plt.plot(test_loss_master[0:20], label='test')\n",
        "plt.plot(val_loss_master[0:20], label='val')\n",
        "diff = [x - y for x, y in zip(val_loss_master, test_loss_master)]\n",
        "print(diff)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "#around 5-6 epochs --> test loss remains constant --> meaning we start to overfit.\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.09702659718101891, 0.1017613620257869, 0.12122903344281788, 0.08493222048918136, 0.036289415568531824, 0.01962416453197835, 0.014794777477726617, 0.012405152743231063, 0.008995218974898855, 0.008984706177818214, 0.009167838170028642, 0.009750708392354701, 0.009387188842843064, 0.009627981280030395, 0.011366766235323844, 0.011648653164657352, 0.01160267690726946, 0.012526022760891431, 0.014320260980909771, 0.01352211416330773, 0.015408571696543416, 0.01680166596442545, 0.01667333623257239, 0.016328650919555376, 0.015811035734233037, 0.015791357279300366, 0.014840487588203555, 0.015301000512009444, 0.01529912302110581, 0.015412473144679195, 0.015077513820531352, 0.013874443039035067, 0.014338748609118324, 0.013967562471025263, 0.013979119361089198, 0.013537312762433529, 0.013615039080980718, 0.013752107295775584, 0.013079587305858897, 0.013446137091225219, 0.013179038332834292, 0.011358033845517146, 0.013048661555244534, 0.014266232773140208, 0.012387060466275357, 0.013661023474384915, 0.014404556893280684, 0.013313961294742493, 0.0130723522500521, 0.013600534148431098, 0.014379900118849598, 0.012293895756688822, 0.012078920333417176, 0.013135537377718665, 0.01512585634848218, 0.014316559895314662, 0.015081701360470712, 0.015578881060391514, 0.014112527434780642, 0.016078945911403797, 0.016316525948860017, 0.015187303947516329, 0.01731924508974303, 0.015653030693879133, 0.016791193220071166, 0.016701885312257247, 0.01519604022661225, 0.016462102158956604, 0.015617614738695607, 0.015969115991517735, 0.016708828266174813, 0.015410266188825572, 0.01751990465428066, 0.01810199845541105, 0.01830334705370129, 0.01699794225753659, 0.018245740936774113, 0.01769625228914462, 0.017218695960848684, 0.018326593175317263, 0.01716457887213818, 0.017973158927967692, 0.01858406156059933, 0.018515479193886297, 0.019159847557967624, 0.01908314148814705, 0.019396233618831915, 0.01900963202375494, 0.02070669832990013, 0.021289895590498653, 0.01963582744531256, 0.019866502665706554, 0.01928468693113372, 0.020215871073263614, 0.02113337170902474, 0.020825016524741002, 0.021813594721017404, 0.02026352959636113, 0.022514360465677896, 0.021425877658046266, 0.021424646627668853, 0.023802196597072056, 0.02299002286965557, 0.02298638759069649, 0.02235703609031603, 0.023795822698375324, 0.022120040162821986, 0.02309820033337029, 0.023758191966872677, 0.024495245029887758, 0.021836324687656727, 0.021236829871709495, 0.019990002943435448, 0.02172260045053742, 0.02301231339958376, 0.024047916951839055, 0.022770931558817153, 0.022644898692062543, 0.023090269882354075, 0.02395996062695327, 0.022558674331125572, 0.023758302846575652, 0.02187099930755909, 0.022398822373890903, 0.024222406294606702, 0.022749805449486793, 0.024599129818184906, 0.023224128631899488, 0.023081521014971074, 0.023829242283658347, 0.023275276064522954, 0.024120492131507132, 0.025132974123251772, 0.024316546647200288, 0.024523836158319656, 0.02468280201768347, 0.023063092687367726, 0.023699288453215117, 0.02394956401306536, 0.024814048841710568, 0.024043415966462978, 0.024789458288402066, 0.024673665388972754, 0.023748683290792827, 0.02492037724932894, 0.02297916762037855, 0.025037967558231622, 0.02700033611074959, 0.025527829150694736, 0.02655380369074911]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRfSUnBW--9f"
      },
      "source": [
        "### Question 7: Matrix Factorization (MF) based CF (number of latent factors)\n",
        "\n",
        "Run the MF model for different number of latent factors $K = \\{4, 16, 64, 128\\}$. Plot the variation in test MSE error with respect to $K$. What do you observe? \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DV2UJFUn--9g"
      },
      "source": [
        "def trainWithK(n_factors):\n",
        "    lr = 1e-3\n",
        "    batch_size = 1024\n",
        "\n",
        "    model_MF = MatrixFactorization(model_CF.n_users, model_CF.n_items, n_factors=n_factors, bias=False)\n",
        "\n",
        "    loss_fn = torch.nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model_MF.parameters(), lr=lr, weight_decay=1e-4)\n",
        "\n",
        "    train_ratings = train[['user_id', 'movie_id', 'rating']].values\n",
        "    test_ratings = test[['user_id', 'movie_id', 'rating']].values\n",
        "\n",
        "    def test_model(model_MF, test_ratings):\n",
        "        n_batches = len(test_ratings) // batch_size\n",
        "        preds, targets = [], []\n",
        "        for b in range(n_batches):\n",
        "            batch_data = test_ratings[(b* batch_size) : (b+1)* batch_size]        \n",
        "            batch_users, batch_items, batch_ratings = batch_data[:, 0], batch_data[:, 1], batch_data[:, 2]\n",
        "            user, item = torch.LongTensor(batch_users), torch.LongTensor(batch_items)\n",
        "            pred = model_MF.predict(user, item).detach()\n",
        "            pred = np.clip(pred, 0, 5)\n",
        "            preds.append(pred)\n",
        "            targets.append(batch_ratings)\n",
        "        preds, targets = np.concatenate(preds), np.concatenate(targets)\n",
        "        test_loss = loss_fn(torch.tensor(preds), torch.tensor(targets)).item()\n",
        "        print (\"test loss: \", test_loss)\n",
        "        return test_loss\n",
        "\n",
        "    train_loss_master = []\n",
        "    test_loss_master = []\n",
        "\n",
        "    for epoch in range(0, 150):\n",
        "        train_loss = 0.0\n",
        "        n_batches = len(train_ratings) // batch_size\n",
        "        if train_ratings % batch_size is not 0:\n",
        "            n_batches += 1\n",
        "        np.random.shuffle(train_ratings)\n",
        "        for b in range(n_batches):\n",
        "            batch_data = train_ratings[(b* batch_size) : (b+1)* batch_size]\n",
        "            # get user, item and rating data\n",
        "            batch_users, batch_items, batch_ratings = batch_data[:, 0], batch_data[:, 1], batch_data[:, 2]\n",
        "            user, item = torch.LongTensor(batch_users), torch.LongTensor(batch_items)\n",
        "            rating = torch.FloatTensor(batch_ratings)\n",
        "            optimizer.zero_grad()\n",
        "            model_MF.zero_grad()\n",
        "            \n",
        "            # predict\n",
        "            prediction = model_MF(user, item)\n",
        "            loss = loss_fn(prediction, rating)\n",
        "\n",
        "            # backpropagate\n",
        "            loss.backward()\n",
        "\n",
        "            # update weights\n",
        "            optimizer.step()\n",
        "            \n",
        "            train_loss += loss.item()\n",
        "            \n",
        "        print (\"epoch {}: train loss {}\".format(epoch, train_loss/n_batches))\n",
        "        #train_loss_master.append(train_loss/n_batches)\n",
        "        test_loss_master.append(test_model(model_MF, test_ratings))    \n",
        "    return test_loss_master"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run the mf model for latent factors 4, 16, 64, 128\n",
        "\n",
        "#initialise a result matrix of 4 rows and undefined columns\n",
        "result = np.zeros((4, 150))\n",
        "\n",
        "#append the result to the result matrix\n",
        "result[0] = trainWithK(4)\n",
        "result[1] = trainWithK(16)\n",
        "result[2] = trainWithK(64)\n",
        "result[3] = trainWithK(128)\n",
        "\n",
        "#plot the result for each latent factor 4, 16, 64, 128\n",
        "\n",
        "#for each row of the result matrix, plot the test loss\n",
        "plt.plot(result[0], label='4')\n",
        "plt.plot(result[1], label='16')\n",
        "plt.plot(result[2], label='64')\n",
        "plt.plot(result[3], label='128')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ifvNIcwwrsaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(result[0][0:20], label='4')\n",
        "plt.plot(result[1][0:20], label='16')\n",
        "plt.plot(result[2][0:20], label='64')\n",
        "plt.plot(result[3][0:20], label='128')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tIuASu0Rt7qO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQxxQkN1--9g"
      },
      "source": [
        "### Question 8: Matrix Factorization (MF) based CF (batch size)\n",
        "Model performance depends a lot of batch size and learning rate. What happens when you change the batch size from 2048? Try smaller (16, 64) and larger batch sizes (4096). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49Dz6xrc--9g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "09eeefdb-367e-41d3-f5a5-c59c24640dc0"
      },
      "source": [],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-25-75ee566995b4>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1qg_9NTQjJGlXRiilhvVy05LI7tBPiJLs#scrollTo=49Dz6xrc--9g)\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    }
  ]
}